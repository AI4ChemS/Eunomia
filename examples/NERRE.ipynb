{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b75ea4-6a1d-4105-8d95-dae67a0679a0",
   "metadata": {},
   "source": [
    "## Loading test data obtained from matscholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0c45e16-70f8-4ef0-a932-6776e14c3533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "def read_jsonl(filename):\n",
    "    \"\"\"\n",
    "    Read a jsonlines file into a list of dictionaries.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to input file.\n",
    "\n",
    "    Returns:\n",
    "        ([dict]): List of dictionaries.\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        samples = []\n",
    "        for l in lines:\n",
    "            samples.append(json.loads(l))\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6724c222-2fdd-49b5-92ed-bab8001e0bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['prompt', 'completion', 'gpt3_completion'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_annotations_file = '../data/NERRE/mof_results/run_1.jsonl'\n",
    "run = read_jsonl(general_annotations_file)\n",
    "run[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a8e9b9a-aa3b-463f-a494-51a073ce0435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bimetallic MOFs (H3O)x[Cu(MF6)(pyrazine)2]·(4 − x)H2O (M = V4+, x = 0; M = Ga3+, x = 1): co-existence of ordered and disordered quantum spins in the V4+ system\\nThe title compounds are bimetallic MOFs containing [Cu(pyz)2]2+ square lattices linked by MF6n− octahedra. In each, only the Cu2+ spins exhibit long-range magnetic order below 3.5 K (M = V4+) and 2.6 K (M = Ga3+). The V4+ spins remain disordered down to 0.5 K.\\n\\n###\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_input = run[3]['prompt']\n",
    "text_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59ac2e21-d4cd-46f7-8ff3-1837c7204652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eunomia\n",
    "docs_processor = eunomia.LoadDoc(text_input=text_input)\n",
    "sliced_pages = docs_processor.process(chunk_size=2000, chunk_overlap=5, chunking_type='fixed-size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e786aa1-6cd0-4aca-b3d7-d3af77ba33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "Embedding_model = 'text-embedding-ada-002'\n",
    "faiss_index = FAISS.from_documents(sliced_pages, OpenAIEmbeddings(model=Embedding_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e2ddb789-e5bc-4aff-9dc7-47e327530bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTS_FROZEN = ['name_of_mof', 'mof_formula', 'mof_description', 'guest_species', 'applications']\n",
    "ROOT = (\"name_of_mof\",)\n",
    "LINK_DELIMITER = \"|||\"\n",
    "\n",
    "\n",
    "ENTS_FROZEN_NOROOT = [e for e in ENTS_FROZEN if e not in ROOT]\n",
    "ENTS_LINKS_FROZEN = [f\"{root}{LINK_DELIMITER}{e}\" for e in ENTS_FROZEN_NOROOT for root in ROOT]\n",
    "\n",
    "def evlaute_model_instance(prompt ,test_json, gold_json, model='Eunomia'):\n",
    "\n",
    "    exact_matches = 0\n",
    "    unparsable = 0\n",
    "    total = 0\n",
    "    \n",
    "    ent_scores_test = {e: [] for e in ENTS_FROZEN}\n",
    "    ent_scores_gold = {e: [] for e in ENTS_FROZEN}\n",
    "    \n",
    "    subdict = {\"test_correct_triplets\": 0, \"test_retrieved_triplets\": 0, \"gold_retrieved_triplets\": 0}\n",
    "    links_scores = {el: copy.deepcopy(subdict) for el in ENTS_LINKS_FROZEN}\n",
    "\n",
    "    # if test_json:\n",
    "    #     test_accounting = ent_json_to_word_basis_sets(test_json)\n",
    "    # else:\n",
    "    #     test_accounting = ent_json_to_word_basis_sets({}, return_empty=True)\n",
    "    # with open(path, 'r') as f:\n",
    "    #     result = json.load(f)\n",
    "    # test_json = result[model]\n",
    "    # gold_json = result['ground-truth']\n",
    "    test_accounting = ent_json_to_word_basis_sets(test_json)\n",
    "    # gold_json = json.loads(gold_json.replace(\"\\n\\nEND\\n\\n\", \"\").strip())\n",
    "    gold_accounting = ent_json_to_word_basis_sets(gold_json)\n",
    "    for etype in ENTS_FROZEN:\n",
    "        ent_accounting_copy = copy.deepcopy(test_accounting[etype])\n",
    "        \n",
    "        n_prompt_words = len([w for w in prompt.split(\" \") if w])\n",
    "        n_unlabelled_words = copy.deepcopy(n_prompt_words)\n",
    "        for ew in gold_accounting[etype]:\n",
    "    \n",
    "            # Account for true positives\n",
    "            if ew in test_accounting[etype]:\n",
    "                ent_scores_test[etype].append(1)\n",
    "                ent_scores_gold[etype].append(1)\n",
    "                ent_accounting_copy.remove(ew)\n",
    "                n_unlabelled_words -= 1\n",
    "            # account for false negatives\n",
    "            else:\n",
    "                ent_scores_test[etype].append(0)\n",
    "                ent_scores_gold[etype].append(1)\n",
    "                n_unlabelled_words -= 1\n",
    "    \n",
    "        # Among the remaining test accounting words, only false positives\n",
    "        # should remain in the set\n",
    "        for ew in ent_accounting_copy:\n",
    "            ent_scores_test[etype].append(1)\n",
    "            ent_scores_gold[etype].append(0)\n",
    "            n_unlabelled_words -= 1\n",
    "    \n",
    "        # the only labels remaining are true negatives\n",
    "        ent_scores_test[etype] += [0] * n_unlabelled_words\n",
    "        ent_scores_gold[etype] += [0] * n_unlabelled_words\n",
    "    \n",
    "    for elinktype in ENTS_LINKS_FROZEN:\n",
    "        gold_triples = gold_accounting[elinktype]\n",
    "        test_triples = test_accounting[elinktype]\n",
    "    \n",
    "        n_correct_triples = len([e for e in test_triples if e in gold_triples])\n",
    "        links_scores[elinktype][\"test_correct_triplets\"] += n_correct_triples\n",
    "        links_scores[elinktype][\"test_retrieved_triplets\"] += len(test_triples)\n",
    "        links_scores[elinktype][\"gold_retrieved_triplets\"] += len(gold_triples)\n",
    "\n",
    "    classification_results = {\"ents\": {}, \"links\": {}}\n",
    "    from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "    from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "    for etype in ENTS_FROZEN:\n",
    "        gold_arr = ent_scores_gold[etype]\n",
    "        test_arr = ent_scores_test[etype]\n",
    "            # Check if both arrays are zeros. If so, set recall to 1.\n",
    "        if sum(test_arr) == 0 and sum(gold_arr) == 0:\n",
    "            print(gold_arr , etype)\n",
    "            print(test_arr , etype)\n",
    "            recall = 1.0\n",
    "            precision = 1.0\n",
    "            f1 = 1.0\n",
    "        else:\n",
    "            recall = np.round(recall_score(gold_arr, test_arr),3)\n",
    "            percision = np.round(precision_score(gold_arr, test_arr),3)\n",
    "            f1 = np.round(f1_score(gold_arr, test_arr),3)\n",
    "        subdict = {\"recall\": 0, \"precision\": 0, \"f1\": 0}\n",
    "        subdict[\"recall\"] = recall\n",
    "        subdict[\"precision\"] = percision\n",
    "        subdict[\"f1\"] = f1\n",
    "        classification_results[\"ents\"][etype] = subdict\n",
    "    return classification_results\n",
    "\n",
    "def check_equivalence_of_entries(gold_entry, test_entry):\n",
    "    ## Entries are a list of dictionaries\n",
    "    ## We first order each list, then each dictionary, then compare strings\n",
    "\n",
    "\n",
    "    ### order list by formula key\n",
    "    gold_entry = sorted(gold_entry, key=lambda x: x.get('formula', ''))\n",
    "    test_entry = sorted(test_entry, key=lambda x: x.get('formula', ''))\n",
    "\n",
    "    ### order each dictionary by keys\n",
    "    gold_entry = [dict(sorted(d.items())) for d in gold_entry]\n",
    "    test_entry = [dict(sorted(d.items())) for d in test_entry]\n",
    "\n",
    "    ### compare strings\n",
    "    return str(gold_entry) == str(test_entry)\n",
    "\n",
    "def ent_json_to_word_basis_sets(ent_json, return_empty=False):\n",
    "    \"\"\"\n",
    "    Where ent_json is multiple entries in a list\n",
    "\n",
    "    Return all entities and links in a set-based word basis\n",
    "    \"\"\"\n",
    "    # Must account for these in a weird way because the entries are not ordered :(\n",
    "    to_account = {e: set() for e in ENTS_FROZEN + ENTS_LINKS_FROZEN}\n",
    "\n",
    "    if return_empty:\n",
    "        return to_account\n",
    "\n",
    "    for entry in ent_json:\n",
    "        root_accounting = {root: set() for root in ROOT}\n",
    "        for etype in ENTS_FROZEN:\n",
    "            ent_strs = entry[etype]\n",
    "            if isinstance(ent_strs, str):\n",
    "                for w in ent_str_to_words(ent_strs):\n",
    "                    to_account[etype].add(w)\n",
    "                if etype in ROOT and ent_strs:\n",
    "                    # Formulae/roots must be counted as single words\n",
    "                    root_accounting[etype].add(ent_strs)\n",
    "                    # root_accounting[etype] = root_accounting[etype].union(set(ent_str_to_words(ent_strs)))\n",
    "            elif isinstance(ent_strs, list):\n",
    "                for ent_str in ent_strs:\n",
    "                    for w in ent_str_to_words(ent_str):\n",
    "                        to_account[etype].add(w)\n",
    "            else:\n",
    "                raise ValueError(f\"Ent strings was a weird type: {type(ent_strs)}, {ent_strs}\")\n",
    "\n",
    "        # Add links\n",
    "        for root, accounting in root_accounting.items():\n",
    "            if accounting:\n",
    "                for e in ENTS_FROZEN_NOROOT:\n",
    "                    ent_strs = entry[e]\n",
    "                    words = []\n",
    "                    if isinstance(ent_strs, str):\n",
    "                        words = ent_str_to_words(ent_strs)\n",
    "                    elif isinstance(ent_strs, list):\n",
    "                        for ent_str in ent_strs:\n",
    "                            words += ent_str_to_words(ent_str)\n",
    "                    else:\n",
    "                        raise ValueError(f\"Ent strings was a weird type: {type(ent_strs)}, {ent_strs}\")\n",
    "\n",
    "                    if words:\n",
    "                        for f in accounting:\n",
    "                            for w in words:\n",
    "                                # avoid self-links\n",
    "                                if f != w:\n",
    "                                    to_account[f\"{root}{LINK_DELIMITER}{e}\"].add(f\"{f}{LINK_DELIMITER}{w}\")\n",
    "    return to_account\n",
    "\n",
    "def ent_str_to_words(ent):\n",
    "    stripped =  [e.strip() for e in ent.split(\" \")]\n",
    "    return [e for e in stripped if e]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ec05b3-19bd-4584-8032-17f641901aaf",
   "metadata": {},
   "source": [
    "## General Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce14e968-380e-4d42-a68e-dc87544d2efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, tool\n",
    "\n",
    "\n",
    "# this is the general case\n",
    "prompt = \"\"\"You are an expert chemist. Read context and answer the following questions:\n",
    "name of material? chemical formula? applications? material description? guest species?\n",
    "\n",
    "\n",
    "There may be more than a single material in the context. If so, answer all the questions for each one you find.\n",
    "\n",
    "Your findings should be structured like this:\n",
    "\n",
    "[{\"acronym\": other names mentioned for a material/formula that actually exists in the context provided.\n",
    "\n",
    "\"applications\" : list of applications or high-level use cases or major property classes for the material. \n",
    "Applications may represent different levels of device-level implementation.\n",
    "\n",
    "\"name\": name of the material.\n",
    "\n",
    "\"formula\": chemical formula of the material.\n",
    "\n",
    "\"structure_or_phase\": list of entities that directly imply the crystalline structure or symmetry of the material. \n",
    "Crystal systems such as \"cubic\" or \"tetragonal\", structure names such as \"rutile\" or \"NASICON\", and space groups \n",
    "such as \"Fd3m\" or \"space group No. 93\" are all extracted in this field.\n",
    "\n",
    "\"description\": list of details about a material’s processing history, defects, modifications, or the sample’s morphology.}]\n",
    "\n",
    "If the context don't mention each item, leave them empty. Do not make up answers and use the exact words from the context. \n",
    "Format the output into a python list of JSONs.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "@tool\n",
    "def read_context(input):\n",
    "    '''\n",
    "    Input the users original prompt and get context to answer to questions.\n",
    "    Always search for the answers using this tool first, don't make up answers yourself.\n",
    "    '''\n",
    "    from langchain.llms import OpenAI\n",
    "    k = 5\n",
    "    min_k = 4  # Minimum limit for k\n",
    "    llm = OpenAI(temperature=0, model_name='gpt-4')  \n",
    "    result = eunomia.RetrievalQABypassTokenLimit(prompt, faiss_index, k=k, min_k=min_k, llm=llm,\n",
    "                         search_type=\"mmr\", fetch_k=50, chain_type=\"stuff\", memory=None)\n",
    "    return result\n",
    "\n",
    "    \n",
    "\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import OutputFixingParser, PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# @tool\n",
    "def format_output(answer):\n",
    "    \"\"\"\n",
    "    Format the agent's answer into a python list of JSONs\n",
    "    \"\"\"\n",
    "\n",
    "    class Material(BaseModel):\n",
    "        \"\"\"Pydantic data model for a Material.\"\"\"\n",
    "        acronym: str = Field(description=\"acronym of a Material\")\n",
    "        applications: list = Field(description=\"applications of a Material\")\n",
    "        name: str = Field(description=\"name of a Material\")\n",
    "        formula: str = Field(description=\"formula of a Material\")\n",
    "        structure_or_phase: list = Field(description=\"structure_or_phase of a Material\")\n",
    "        description: list = Field(description=\"description of a Material\")\n",
    "\n",
    "    class MaterialList(BaseModel):\n",
    "        \"\"\"Pydantic data model for a list of Materials.\"\"\"\n",
    "\n",
    "        Materials: List[Material]\n",
    "\n",
    "    # Initialize a Pydantic output parser for the Material list model\n",
    "    parser = PydanticOutputParser(pydantic_object=MaterialList)\n",
    "\n",
    "    # Enhance the parser with capabilities to handle specific LLM outputs\n",
    "    llm_parser = OutputFixingParser.from_llm(\n",
    "        parser=parser, llm=ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "    )\n",
    "\n",
    "    # Check if result is a valid JSON string\n",
    "    try:\n",
    "        json.loads(answer, strict=False)\n",
    "    except json.JSONDecodeError:\n",
    "        # If not, convert it to a valid JSON string\n",
    "        answer = json.dumps({\"dummy_key\": answer})\n",
    "    # Try parsing the answer using the enhanced parser\n",
    "    try:\n",
    "        parsed_result = llm_parser.parse(answer)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Failed to parse Material: {e}\")\n",
    "\n",
    "    # Construct a dictionary with materials' details using comprehension\n",
    "    parsed_response = [\n",
    "        {   \"acronym\": material.acronym,\n",
    "            \"applications\": material.applications,\n",
    "            \"name\": material.name,\n",
    "            \"formula\": material.formula,\n",
    "            \"structure_or_phase\": material.structure_or_phase,\n",
    "            \"description\": material.description\n",
    "        }\n",
    "        for material in parsed_result.Materials\n",
    "    ]\n",
    "\n",
    "    return parsed_response\n",
    "\n",
    "\n",
    "\n",
    "from eunomia.agents import Eunomia\n",
    "agent = Eunomia(tools=[read_context],\n",
    "                model='gpt-4', get_cost=True, temp=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f42bb7-a8a7-4ccf-a0b1-54a15bd7b5dd",
   "metadata": {},
   "source": [
    "## Metal–organic framework (MOF) schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "49877627-28f9-4949-b265-d278de055ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nanoporous Ag2O photocatalysts based on copper terephthalate metal–organic frameworks\\nWe report the nanoporous Ag2O based on the copper terephthalate metal–organic frameworks (Ag2O/MOF) photocatalyst. Ag2O/MOF nanostructure was formed via oxygen treatment of Ag/MOF nanoparticles. The resulting Ag2O/MOF photocatalysts were characterised by various techniques. Results showed that the synthesised Ag2O/MOF nanocomposite exhibited dramatic separation of photoinduced electron/hole and excellent photodegradation activity under visible light irradiation. The degradation rate of acid blue 92 using Ag2O/MOF nanocomposite is found to be higher than that using pure MOF and Ag/MOF. It was divulged that the photodegradation rate is increased by oxygen treatment of Ag in Ag/MOF structure. The possible mechanism for the enhanced photocatalytic properties of the Ag2O/MOF nanocomposite was also discussed. Similar to the mechanism proposed in the photodegradation by the other semiconductors, we propose that the photodegradation mechanism involves the generation of nonselective hydroxyl radicals concluding from the photoexcitation of the Ag2O semiconductor. All these results suggested that the catalysis occurs on the surface of nanocomposite, whose surface are covered with the Ag2O photocatalysts. The observed results on the both rate and efficiency of photodegradation are discussed in terms of (1) the surface area of synthesised MOF covered with Ag (Ag2O) and (2) separation of e−/h+ pairs. Our research paves the way to design and develop highly effective and stable visible light-induced photocatalysts for the degradation of organic pollutants for water purification.\\n\\n###\\n\\n'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mof_annotations_file = '../data/NERRE/mof_results/run_1.jsonl'\n",
    "run = read_jsonl(mof_annotations_file)\n",
    "m = 10\n",
    "text_input = run[m]['prompt']\n",
    "ground_truth = run[m]['completion']\n",
    "prompt = run[m][\"prompt\"].replace(\"\\n\\n###\\n\\n\", \"\").strip()\n",
    "text_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b98daae5-0f72-4f3f-ab96-4147703d7a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Nanoporous Ag2O photocatalysts based on copper terephthalate metal–organic frameworks\\nWe report the nanoporous Ag2O based on the copper terephthalate metal–organic frameworks (Ag2O/MOF) photocatalyst.\\n\\nAg2O/MOF nanostructure was formed via oxygen treatment of Ag/MOF nanoparticles.\\n\\nThe resulting Ag2O/MOF photocatalysts were characterised by various techniques.\\n\\nResults showed that the synthesised Ag2O/MOF nanocomposite exhibited dramatic separation of photoinduced electron/hole and excellent photodegradation activity under visible light irradiation.', metadata={'source': 'local'}),\n",
       " Document(page_content='The degradation rate of acid blue 92 using Ag2O/MOF nanocomposite is found to be higher than that using pure MOF and Ag/MOF.\\n\\nIt was divulged that the photodegradation rate is increased by oxygen treatment of Ag in Ag/MOF structure.\\n\\nThe possible mechanism for the enhanced photocatalytic properties of the Ag2O/MOF nanocomposite was also discussed.', metadata={'source': 'local'}),\n",
       " Document(page_content='Similar to the mechanism proposed in the photodegradation by the other semiconductors, we propose that the photodegradation mechanism involves the generation of nonselective hydroxyl radicals concluding from the photoexcitation of the Ag2O semiconductor.\\n\\nAll these results suggested that the catalysis occurs on the surface of nanocomposite, whose surface are covered with the Ag2O photocatalysts.\\n\\nThe observed results on the both rate and efficiency of photodegradation are discussed in terms of (1) the surface area of synthesised MOF covered with Ag (Ag2O) and (2) separation of e−/h+ pairs.', metadata={'source': 'local'}),\n",
       " Document(page_content='Our research paves the way to design and develop highly effective and stable visible light-induced photocatalysts for the degradation of organic pollutants for water purification.\\n\\n###', metadata={'source': 'local'})]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eunomia\n",
    "docs_processor = eunomia.LoadDoc(text_input=text_input)\n",
    "sliced_pages = docs_processor.process(chunk_size=600, chunk_overlap=50, chunking_type='NLTK')\n",
    "sliced_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "14ea34b7-27e3-4739-9a63-148a91884af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.schema import Document\n",
    "# pages = Document(page_content=text_input, metadata={\"source\": \"local\"})\n",
    "# pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "43c017be-b5b4-4b3d-9be9-0eb71c29b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "Embedding_model = 'text-embedding-ada-002'\n",
    "faiss_index = FAISS.from_documents(sliced_pages, OpenAIEmbeddings(model=Embedding_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "67ae6f3a-0e3d-4210-939c-484fbac6efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [{\"name_of_mof\": name of the MOF\n",
    "\n",
    "# \"mof_formula\": chemical formula of the MOF.\n",
    "\n",
    "# \"mof_description\": list of details about a MOF’s processing history, defects, modifications, or the sample’s morphology.\n",
    "\n",
    "# \"guest_species\": list of chemical species that have been incorporated, stored, or absorbed in the MOF.\n",
    "\n",
    "# \"applications\" : list of applications or high-level use cases or major property classes for the MOF.\n",
    "# Applications may represent different levels of device-level implementation. Make the answer short like: \"gas-separation\", \"heterogeneous\n",
    "# catalyst\", \"Diels-Alder reactions\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9d0e1a9f-d3e7-4719-9f0e-382ac35b1e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, tool\n",
    "\n",
    "# this is the MOF case\n",
    "prompt_mof = \"\"\"You are an expert chemist. Read context, find all the MOFs and answer the following questions for each one:\n",
    "name of MOF? MOF chemical formula? MOF description? guest species? applications?\n",
    "\n",
    "Use this rules: \n",
    "MOF names cannot be general like: \"copper terephthalate metal–organic frameworks\".\n",
    "Valid chemical formula should be similar to: \"Zn3(BTC)2\", \"Zn4O(1,4-benzenedicarboxylate)3\" or \"[Ln(2,5-pzdc)(ox)0.5(H2O)2] 4.5H2O (1-Ln; Ln = Nd, Sm, Eu, Gd, Tb, Dy)\".\n",
    "MOF description is a list of details about a MOF’s processing history, defects, modifications, or the sample’s morphology.\n",
    "Guest species is a list of chemical molecules (like water, hydrogen, CO2, CH4, N2, H2, VOCs, etc.) that have been incorporated, stored, or absorbed in the MOF.\n",
    "Applications is a list summary of applications or high-level use cases or major property classes for the MOF.\n",
    "Applications may represent different levels of device-level implementation. Answer shortly short like: \"gas-separation\", \"heterogeneous\n",
    "catalyst\", \"Diels-Alder reactions\"\n",
    "\n",
    "There may be more than a single MOF in the context. If so, answer all the questions for each one you find.\n",
    "\n",
    "Your findings should be structured like this:\n",
    "\n",
    "[{\"name_of_mof\": ...\n",
    "\n",
    "\"mof_formula\": ...\n",
    "\n",
    "\"mof_description\": [...]\n",
    "\n",
    "\"guest_species\": [...]\n",
    "\n",
    "\"applications\" : [...]}]\n",
    "\n",
    "\n",
    "If the context don't mention each item, leave them empty and use the following format:\n",
    "\"name_of_mof\": \"\"\n",
    "\"mof_formula\": \"\"\n",
    "\"mof_description\": [\"\"]\n",
    "\"guest_species\": [\"\"]\n",
    "\"applications\" : [\"\"]\n",
    "\n",
    "Do not make up answers and use the exact words from the context. \n",
    "Format the output into a python list of JSONs.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "@tool\n",
    "def read_context(input):\n",
    "    '''\n",
    "    Input the users original prompt and get context to answer to questions.\n",
    "    Always search for the answers using this tool first, don't make up answers yourself.\n",
    "    '''\n",
    "    from langchain.llms import OpenAI\n",
    "    k = 10\n",
    "    min_k = 4  # Minimum limit for k\n",
    "    llm = OpenAI(temperature=0, model_name='gpt-4')  \n",
    "    result = eunomia.RetrievalQABypassTokenLimit(prompt_mof, faiss_index, k=k, min_k=min_k, llm=llm,\n",
    "                         search_type=\"mmr\", fetch_k=50, chain_type=\"stuff\", memory=None)\n",
    "    return result\n",
    "\n",
    "    \n",
    "\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import OutputFixingParser, PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# @tool\n",
    "def format_output(answer):\n",
    "    \"\"\"\n",
    "    Format the agent's answer into a python list of JSONs\n",
    "    \"\"\"\n",
    "\n",
    "    class MOF(BaseModel):\n",
    "        \"\"\"Pydantic data model for a MOF.\"\"\"\n",
    "        name: str = Field(description=\"name of a MOF\")\n",
    "        formula: str = Field(description=\"formula of a MOF\")\n",
    "        description: list = Field(description=\"description of a MOF\")\n",
    "        guest_species: list = Field(description=\"guest_species of a MOF\")\n",
    "        applications: list = Field(description=\"applications of a MOF\")\n",
    "\n",
    "    class MOFList(BaseModel):\n",
    "        \"\"\"Pydantic data model for a list of MOFs.\"\"\"\n",
    "\n",
    "        MOFs: List[MOF]\n",
    "\n",
    "    # Initialize a Pydantic output parser for the MOF list model\n",
    "    parser = PydanticOutputParser(pydantic_object=MOFList)\n",
    "\n",
    "    # Enhance the parser with capabilities to handle specific LLM outputs\n",
    "    llm_parser = OutputFixingParser.from_llm(\n",
    "        parser=parser, llm=ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "    )\n",
    "\n",
    "    # Check if result is a valid JSON string\n",
    "    try:\n",
    "        json.loads(answer, strict=False)\n",
    "    except json.JSONDecodeError:\n",
    "        # If not, convert it to a valid JSON string\n",
    "        answer = json.dumps({\"dummy_key\": answer})\n",
    "    # Try parsing the answer using the enhanced parser\n",
    "    try:\n",
    "        parsed_result = llm_parser.parse(answer)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Failed to parse MOF: {e}\")\n",
    "\n",
    "    # Construct a dictionary with MOFs' details using comprehension\n",
    "    parsed_response = [\n",
    "        {   \n",
    "            \"name_of_mof\": MOF.name,\n",
    "            \"mof_formula\": MOF.formula,\n",
    "            \"mof_description\": MOF.description,\n",
    "            \"guest_species\": MOF.guest_species,\n",
    "            \"applications\": MOF.applications\n",
    "        }\n",
    "        for MOF in parsed_result.MOFs\n",
    "    ]\n",
    "\n",
    "    return parsed_response\n",
    "\n",
    "\n",
    "\n",
    "from eunomia.agents import Eunomia\n",
    "agent = Eunomia(tools=[read_context],\n",
    "                model='gpt-4', get_cost=True, temp=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee92cef1-880a-425c-b7d0-a770e9716b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to read the context to find the information about MOFs.\n",
      "Action: read_context\n",
      "Action Input: You are an expert chemist. Read context, find all the MOFs and answer the following questions for each one:\n",
      "name of MOF? MOF chemical formula? MOF description? guest species? applications?\n",
      "\n",
      "Use this rules: \n",
      "MOF names cannot be general like: \"copper terephthalate metal–organic frameworks\".\n",
      "Valid chemical formula should be similar to: \"Zn3(BTC)2\", \"Zn4O(1,4-benzenedicarboxylate)3\" or \"[Ln(2,5-pzdc)(ox)0.5(H2O)2] 4.5H2O (1-Ln; Ln = Nd, Sm, Eu, Gd, Tb, Dy)\".\n",
      "MOF description is a list of details about a MOF’s processing history, defects, modifications, or the sample’s morphology.\n",
      "Guest species is a list of chemical molecules (like water, hydrogen, CO2, CH4, N2, H2, VOCs, etc.) that have been incorporated, stored, or absorbed in the MOF.\n",
      "Applications is a list summary of applications or high-level use cases or major property classes for the MOF.\n",
      "Applications may represent different levels of device-level implementation. Answer shortly short like: \"gas-separation\", \"heterogeneous\n",
      "catalyst\", \"Diels-Alder reactions\"\n",
      "\n",
      "There may be more than a single MOF in the context. If so, answer all the questions for each one you find.\n",
      "\n",
      "Your findings should be structured like this:\n",
      "\n",
      "[{\"name_of_mof\": ...\n",
      "\n",
      "\"mof_formula\": ...\n",
      "\n",
      "\"mof_description\": [...]\n",
      "\n",
      "\"guest_species\": [...]\n",
      "\n",
      "\"applications\" : [...]}]\n",
      "\n",
      "\n",
      "If the context don't mention each item, leave them empty and use the following format:\n",
      "\"name_of_mof\": \"\"\n",
      "\"mof_formula\": \"\"\n",
      "\"mof_description\": [\"\"]\n",
      "\"guest_species\": [\"\"]\n",
      "\"applications\" : [\"\"]\n",
      "\n",
      "Do not make up answers and use the exact words from the context. \n",
      "Format the output into a python list of JSONs.\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{\"name_of_mof\": \"Ag2O/MOF\",\n",
      "\"mof_formula\": \"\",\n",
      "\"mof_description\": [\"nanoporous\", \"formed via oxygen treatment of Ag/MOF nanoparticles\", \"characterised by various techniques\", \"exhibited dramatic separation of photoinduced electron/hole\", \"excellent photodegradation activity under visible light irradiation\", \"surface are covered with the Ag2O photocatalysts\"],\n",
      "\"guest_species\": [\"\"],\n",
      "\"applications\" : [\"degradation of organic pollutants for water purification\"]},\n",
      "\n",
      "{\"name_of_mof\": \"Ag/MOF\",\n",
      "\"mof_formula\": \"\",\n",
      "\"mof_description\": [\"oxygen treatment increases photodegradation rate\"],\n",
      "\"guest_species\": [\"\"],\n",
      "\"applications\" : [\"\"]}]\u001b[0m\n",
      "Thought:"
     ]
    }
   ],
   "source": [
    "results = agent.run(prompt=prompt_mof)\n",
    "json.loads(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "73814ccc-f3ca-4687-8563-71e2d81cb736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"name_of_mof\": \"\", \"mof_formula\": \"\", \"mof_description\": [\"\"], \"guest_species\": [\"\"], \"applications\" : [\"\"]}]'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8d849bc2-52cd-4676-8c4c-2261bc3bb7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name_of_mof': '',\n",
       "  'mof_formula': '',\n",
       "  'mof_description': [''],\n",
       "  'guest_species': [''],\n",
       "  'applications': ['']}]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4937b84c-0de6-4542-a68b-30a24f290587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name_of_mof': 'Ag2O/MOF',\n",
       "  'mof_formula': 'Ag2O',\n",
       "  'mof_description': ['Nanoporous Ag2O photocatalysts based on copper terephthalate metal–organic frameworks',\n",
       "   'Ag2O/MOF nanostructure was formed via oxygen treatment of Ag/MOF nanoparticles'],\n",
       "  'guest_species': [''],\n",
       "  'applications': ['degradation of organic pollutants for water purification']},\n",
       " {'name_of_mof': 'Ag/MOF',\n",
       "  'mof_formula': 'Ag',\n",
       "  'mof_description': ['Ag/MOF nanoparticles'],\n",
       "  'guest_species': [''],\n",
       "  'applications': ['']}]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_results = format_output(results)\n",
    "parsed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "935ad0c8-a2c4-4a97-b4bb-c3f1c2b72dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Topology-dependent emissive properties of zirconium-based porphyrin MOFs\\nHighly ordered chromophoric linkers positioned within the metal–organic frameworks (MOFs) have the potential to mimic natural light-harvesting complexes. Herein we report topological control over the photophysical properties of MOFs via modular interchromophoric electronic coupling to manifest different steady-state singlet emission spectra and their corresponding fluorescence lifetimes.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "83758113-93cb-48ce-bc42-91d4d271096b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [{\"name_of_mof\": \"\", \"mof_formula\": \"\", \"mof_description\": [\"\"], \"guest_species\": [\"\"], \"applications\": [\"chromatography\"]}]\\n\\nEND\\n\\n'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5060fbff-0bbd-41e0-b08e-8902c9f9ff52",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resultprompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m evlaute_model_instance(\u001b[43mresultprompt\u001b[49m, parsed_results, ground_truth)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'resultprompt' is not defined"
     ]
    }
   ],
   "source": [
    "evlaute_model_instance(resultprompt, parsed_results, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "68de5953-0580-41c9-9867-ec274b5efc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ID =  1\n",
    "i = 10\n",
    "file = f'../data/NERRE/mof_results/{run_ID}/run_{run_ID}_{i}.json'\n",
    "with open(file, 'r') as f:\n",
    "    result = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6c76e44e-ce1a-4ba8-b395-3fedcf3e444e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nanoporous Ag2O photocatalysts based on copper terephthalate metal–organic frameworks\\nWe report the nanoporous Ag2O based on the copper terephthalate metal–organic frameworks (Ag2O/MOF) photocatalyst. Ag2O/MOF nanostructure was formed via oxygen treatment of Ag/MOF nanoparticles. The resulting Ag2O/MOF photocatalysts were characterised by various techniques. Results showed that the synthesised Ag2O/MOF nanocomposite exhibited dramatic separation of photoinduced electron/hole and excellent photodegradation activity under visible light irradiation. The degradation rate of acid blue 92 using Ag2O/MOF nanocomposite is found to be higher than that using pure MOF and Ag/MOF. It was divulged that the photodegradation rate is increased by oxygen treatment of Ag in Ag/MOF structure. The possible mechanism for the enhanced photocatalytic properties of the Ag2O/MOF nanocomposite was also discussed. Similar to the mechanism proposed in the photodegradation by the other semiconductors, we propose that the photodegradation mechanism involves the generation of nonselective hydroxyl radicals concluding from the photoexcitation of the Ag2O semiconductor. All these results suggested that the catalysis occurs on the surface of nanocomposite, whose surface are covered with the Ag2O photocatalysts. The observed results on the both rate and efficiency of photodegradation are discussed in terms of (1) the surface area of synthesised MOF covered with Ag (Ag2O) and (2) separation of e−/h+ pairs. Our research paves the way to design and develop highly effective and stable visible light-induced photocatalysts for the degradation of organic pollutants for water purification.\\n\\n###\\n\\n'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "78cbda5d-6630-41b9-b7b9-cad5844f78d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name_of_mof': {'Ag/MOF', 'Ag2O/MOF'}, 'mof_formula': {'Ag2O', 'Ag'}, 'mof_description': {'formed', 'oxygen', 'treatment', 'on', 'of', 'terephthalate', 'photocatalysts', 'Nanoporous', 'frameworks', 'was', 'nanoparticles', 'Ag2O/MOF', 'Ag2O', 'Ag/MOF', 'metal–organic', 'based', 'via', 'nanostructure', 'copper'}, 'guest_species': set(), 'applications': {'for', 'purification', 'degradation', 'water', 'pollutants', 'of', 'organic'}, 'name_of_mof|||mof_formula': {'Ag/MOF|||Ag', 'Ag2O/MOF|||Ag2O'}, 'name_of_mof|||mof_description': {'Ag2O/MOF|||Nanoporous', 'Ag2O/MOF|||formed', 'Ag2O/MOF|||Ag2O', 'Ag2O/MOF|||based', 'Ag2O/MOF|||Ag/MOF', 'Ag2O/MOF|||on', 'Ag2O/MOF|||was', 'Ag2O/MOF|||of', 'Ag2O/MOF|||frameworks', 'Ag/MOF|||nanoparticles', 'Ag2O/MOF|||nanoparticles', 'Ag2O/MOF|||copper', 'Ag2O/MOF|||nanostructure', 'Ag2O/MOF|||terephthalate', 'Ag2O/MOF|||oxygen', 'Ag2O/MOF|||via', 'Ag2O/MOF|||treatment', 'Ag2O/MOF|||photocatalysts', 'Ag2O/MOF|||metal–organic'}, 'name_of_mof|||guest_species': set(), 'name_of_mof|||applications': {'Ag2O/MOF|||for', 'Ag2O/MOF|||water', 'Ag2O/MOF|||pollutants', 'Ag2O/MOF|||organic', 'Ag2O/MOF|||degradation', 'Ag2O/MOF|||of', 'Ag2O/MOF|||purification'}}\n"
     ]
    }
   ],
   "source": [
    "test_accounting = ent_json_to_word_basis_sets(parsed_results)\n",
    "gold_accounting = ent_json_to_word_basis_sets(result['ground-truth'])\n",
    "print(test_accounting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cbcd0c79-d856-4ea7-a63e-3c06e2fa1d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name_of_mof': {'Ag/MOF', 'Ag2O/MOF'}, 'mof_formula': set(), 'mof_description': {'frameworks', 'terephthalate', 'copper', 'metal–organic'}, 'guest_species': set(), 'applications': {'photodegradation', 'photocatalytic', 'photocatalysts'}, 'name_of_mof|||mof_formula': set(), 'name_of_mof|||mof_description': {'Ag2O/MOF|||copper', 'Ag2O/MOF|||frameworks', 'Ag2O/MOF|||terephthalate', 'Ag2O/MOF|||metal–organic'}, 'name_of_mof|||guest_species': set(), 'name_of_mof|||applications': {'Ag/MOF|||photocatalysts', 'Ag/MOF|||photodegradation', 'Ag2O/MOF|||photodegradation', 'Ag2O/MOF|||photocatalysts', 'Ag2O/MOF|||photocatalytic'}}\n"
     ]
    }
   ],
   "source": [
    "print(gold_accounting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3c22f3b3-cc12-4260-96ff-a5fb5649b90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name_of_mof': 'Ag2O/MOF',\n",
       "  'mof_formula': '',\n",
       "  'mof_description': ['copper terephthalate metal–organic frameworks'],\n",
       "  'guest_species': [''],\n",
       "  'applications': ['photocatalysts', 'photodegradation', 'photocatalytic ']},\n",
       " {'name_of_mof': 'Ag/MOF',\n",
       "  'mof_formula': '',\n",
       "  'mof_description': [''],\n",
       "  'guest_species': [''],\n",
       "  'applications': ['photocatalysts', 'photodegradation']}]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['ground-truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ee872203-aea0-4656-a991-0accced7f1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name_of_mof': 'Ag2O/MOF',\n",
       "  'mof_formula': 'Ag2O',\n",
       "  'mof_description': ['Nanoporous Ag2O photocatalysts based on copper terephthalate metal–organic frameworks',\n",
       "   'Ag2O/MOF nanostructure was formed via oxygen treatment of Ag/MOF nanoparticles'],\n",
       "  'guest_species': [''],\n",
       "  'applications': ['degradation of organic pollutants for water purification']},\n",
       " {'name_of_mof': 'Ag/MOF',\n",
       "  'mof_formula': 'Ag',\n",
       "  'mof_description': ['Ag/MOF nanoparticles'],\n",
       "  'guest_species': [''],\n",
       "  'applications': ['']}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b6aa1ee0-e4de-4380-ab90-fb54bffd470c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] guest_species\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] guest_species\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehra\\anaconda3\\envs\\agent\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ents': {'name_of_mof': {'recall': 1.0, 'precision': 1.0, 'f1': 1.0},\n",
       "  'mof_formula': {'recall': 0.0, 'precision': 0.0, 'f1': 0.0},\n",
       "  'mof_description': {'recall': 1.0, 'precision': 0.211, 'f1': 0.348},\n",
       "  'guest_species': {'recall': 1.0, 'precision': 0.211, 'f1': 1.0},\n",
       "  'applications': {'recall': 0.0, 'precision': 0.0, 'f1': 0.0}},\n",
       " 'links': {}}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evlaute_model_instance(result['prompt'], parsed_results, result['ground-truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "657b50bd-71a9-4e5f-a306-fc0a95f87088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ents': {'name_of_mof': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0},\n",
       "  'mof_formula': {'precision': 0.0, 'recall': 0, 'f1': 0},\n",
       "  'mof_description': {'precision': 0.0, 'recall': 0.0, 'f1': 0},\n",
       "  'guest_species': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0},\n",
       "  'applications': {'precision': 0.0, 'recall': 0.0, 'f1': 0}}}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(result['ground-truth'], parsed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "17bc7a92-28f6-4d2b-ae39-bc3e93e63c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(ground_truth, predicted):\n",
    "    # Initialize results\n",
    "    results = {\"ents\": {}}\n",
    "    \n",
    "    # Define keys to compare\n",
    "    keys = ['name_of_mof', 'mof_formula', 'mof_description', 'guest_species', 'applications']\n",
    "\n",
    "    for key in keys:\n",
    "        TP, FP, FN = 0, 0, 0\n",
    "        \n",
    "        for gt, pred in zip(ground_truth, predicted):\n",
    "            # Counting True Positives\n",
    "            TP += sum([item in pred[key] for item in gt[key]])\n",
    "            # Counting False Positives\n",
    "            FP += sum([item not in gt[key] for item in pred[key]])\n",
    "            # Counting False Negatives\n",
    "            FN += sum([item not in pred[key] for item in gt[key]])\n",
    "\n",
    "        # Calculate precision, recall, and F1 score\n",
    "        precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "        \n",
    "        results[\"ents\"][key] = {\n",
    "            'precision': round(precision, 3),\n",
    "            'recall': round(recall, 3),\n",
    "            'f1': round(f1_score, 3)\n",
    "        }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "95bed13e-2b36-472c-bb10-93ffe5f2e81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [{\"name_of_mof\": \"\", \"mof_formula\": \"\", \"mof_description\": [\"zirconium-based porphyrin MOFs\"], \"guest_species\": [\"\"], \"applications\": [\"photophysical properties\", \"singlet emission\", \"fluorescence\"]}]\\n\\nEND\\n\\n'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9715ab15-889b-43d5-b77c-6942a2f314fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"name_of_mof\": \"NH2-MIL-125\", \"mof_formula\": \"\", \"mof_description\": [\"amine-functionalized MOFs\"], \"guest_species\": [\"\"], \"applications\": [\"photocatalysis\", \"photocatalysts\"]}, {\"name_of_mof\": \"CdS/NH2-MIL-125@TiO2\", \"mof_formula\": \"\", \"mof_description\": [\"amine-functionalized MOFs\"], \"guest_species\": [\"\"], \"applications\": [\"photocatalysis\", \"photocatalysts\"]}]'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"completion\"].replace(\"\\n\\nEND\\n\\n\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e0cdb07-86b0-4e16-86cb-5862190c2719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'A mild one-step method for enhancing optical absorption of amine-functionalized metal-organic frameworks\\nMetal-organic frameworks (MOFs) are of significant interest for photocatalysis using visible light. Here we discuss HOMO/LUMO gap modification of amine-functionalized MOFs through a mild one-step method. DFT calculation reveals the formation of covalent bond between TiO2 and the amine from NH2-MIL-125, narrowing the HOMO/LUMO gap of NH2-MIL-125 by raising its HOMO level. After CdS quantum dots (QDs) deposited on this MOF@TiO2 core-shell structure, this composite catalyst can act as an efficient visible-light-driven catalyst for NO removal. The integral coating of amorphous TiO2 onto MOF octahedrons constructs a mesoporous protection shell upon MOF frameworks, providing a superior accommodation for embedding CdS QDs. Integrating MOF with TiO2 also reduces undesirable electron-hole recombination by facilitating charge transfer to amorphous TiO2. Possible mechanism of photocatalytic oxidation of NO over CdS/NH2-MIL-125@TiO2 catalysts is proposed. This work illustrates the possibility of tuning the optical response of NH2-MOFs under very mild condition, and demonstrates the potential usage of MOF-based heterostructured photocatalysts.\\n\\n###\\n\\n',\n",
       " 'Eunomia': [{'name_of_mof': 'NH2-MIL-125',\n",
       "   'mof_formula': '',\n",
       "   'mof_description': ['HOMO/LUMO gap modification of amine-functionalized MOFs through a mild one-step method',\n",
       "    'formation of covalent bond between TiO2 and the amine',\n",
       "    'narrowing the HOMO/LUMO gap of NH2-MIL-125 by raising its HOMO level',\n",
       "    'integral coating of amorphous TiO2 onto MOF octahedrons constructs a mesoporous protection shell upon MOF frameworks'],\n",
       "   'guest_species': ['CdS quantum dots'],\n",
       "   'applications': ['efficient visible-light-driven catalyst for NO removal']}],\n",
       " 'NERRE': '[{\"name_of_mof\": \"NH2-MIL-125\", \"mof_formula\": \"\", \"mof_description\": [\"amine-functionalized metal-organic frameworks (MOFs)\"], \"guest_species\": [\"\"], \"applications\": [\"photocatalysis\", \"NO removal\", \"catalyst\", \"photocatalytic oxidation of NO\"]}, {\"name_of_mof\": \"CdS/NH2-MIL-125@TiO2\", \"mof_formula\": \"\", \"mof_description\": [\"amine-functionalized metal-organic frameworks (MOFs)\"], \"guest_species\": [\"\"], \"applications\": [\"photocatalysis\", \"NO removal\", \"catalyst\", \"photocatalytic oxidation of NO\"]}]',\n",
       " 'ground-truth': [{'name_of_mof': 'NH2-MIL-125',\n",
       "   'mof_formula': '',\n",
       "   'mof_description': ['amine-functionalized MOFs'],\n",
       "   'guest_species': [''],\n",
       "   'applications': ['photocatalysis', 'photocatalysts']},\n",
       "  {'name_of_mof': 'CdS/NH2-MIL-125@TiO2',\n",
       "   'mof_formula': '',\n",
       "   'mof_description': ['amine-functionalized MOFs'],\n",
       "   'guest_species': [''],\n",
       "   'applications': ['photocatalysis', 'photocatalysts']}]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_json = json.loads( run[0][\"completion\"].replace(\"\\n\\nEND\\n\\n\", \"\").strip())\n",
    "\n",
    "\n",
    "dict = {\n",
    "    'prompt': run[0]['prompt'], 'Eunomia': parsed_results, 'NERRE': run[0]['gpt3_completion'], 'ground-truth': ground_truth_json\n",
    "}\n",
    "\n",
    "with open('../data/NERRE/mof_results/0/run_0_0.json', 'w') as f:\n",
    "    json.dump(dict,f, indent = 4)\n",
    "\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b22e3334-f8a3-4ab2-8a33-2a6965de0a10",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcompletion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\agent\\lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m(),\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[0;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[0;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "json.load(run[0]['completion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e425198-66fe-41f7-8f0e-c6bf3543a173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A mild one-step method for enhancing optical absorption of amine-functionalized metal-organic frameworks\\nMetal-organic frameworks (MOFs) are of significant interest for photocatalysis using visible light. Here we discuss HOMO/LUMO gap modification of amine-functionalized MOFs through a mild one-step method. DFT calculation reveals the formation of covalent bond between TiO2 and the amine from NH2-MIL-125, narrowing the HOMO/LUMO gap of NH2-MIL-125 by raising its HOMO level. After CdS quantum dots (QDs) deposited on this MOF@TiO2 core-shell structure, this composite catalyst can act as an efficient visible-light-driven catalyst for NO removal. The integral coating of amorphous TiO2 onto MOF octahedrons constructs a mesoporous protection shell upon MOF frameworks, providing a superior accommodation for embedding CdS QDs. Integrating MOF with TiO2 also reduces undesirable electron-hole recombination by facilitating charge transfer to amorphous TiO2. Possible mechanism of photocatalytic oxidation of NO over CdS/NH2-MIL-125@TiO2 catalysts is proposed. This work illustrates the possibility of tuning the optical response of NH2-MOFs under very mild condition, and demonstrates the potential usage of MOF-based heterostructured photocatalysts.\\n\\n###\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run[0]['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41180e30-2394-4980-b3b7-eb6cddd93bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [{\"name_of_mof\": \"NH2-MIL-125\", \"mof_formula\": \"\", \"mof_description\": [\"amine-functionalized MOFs\"], \"guest_species\": [\"\"], \"applications\": [\"photocatalysis\", \"photocatalysts\"]}, {\"name_of_mof\": \"CdS/NH2-MIL-125@TiO2\", \"mof_formula\": \"\", \"mof_description\": [\"amine-functionalized MOFs\"], \"guest_species\": [\"\"], \"applications\": [\"photocatalysis\", \"photocatalysts\"]}]\\n\\nEND\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run[0]['completion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06cb7669-62ca-4d38-8639-128158b18a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"name_of_mof\": \"NH2-MIL-125\", \"mof_formula\": \"\", \"mof_description\": [\"amine-functionalized metal-organic frameworks (MOFs)\"], \"guest_species\": [\"\"], \"applications\": [\"photocatalysis\", \"NO removal\", \"catalyst\", \"photocatalytic oxidation of NO\"]}, {\"name_of_mof\": \"CdS/NH2-MIL-125@TiO2\", \"mof_formula\": \"\", \"mof_description\": [\"amine-functionalized metal-organic frameworks (MOFs)\"], \"guest_species\": [\"\"], \"applications\": [\"photocatalysis\", \"NO removal\", \"catalyst\", \"photocatalytic oxidation of NO\"]}]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run[0]['gpt3_completion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9263c3b6-f5e9-483a-9b1d-2007b8102077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [{\"name_of_mof\": \"\", \"mof_formula\": \"(H3O)x[Cu(MF6)(pyrazine)2]·(4 − x)H2O (M = V4+, x = 0; M = Ga3+, x = 1)\", \"mof_description\": [\"\"], \"guest_species\": [\"\"], \"applications\": [\"magnetic\"]}, {\"name_of_mof\": \"\", \"mof_formula\": \"[Cu(pyz)2]2+\", \"mof_description\": [\"\"], \"guest_species\": [\"\"], \"applications\": [\"magnetic\"]}]\\n\\nEND\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run[3]['completion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d18b5b70-4be1-4e73-81ae-ace6b5dc2f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "import copy\n",
    "import tqdm\n",
    "\n",
    "\n",
    "general_annotations_file = '../data/NERRE/mof_results/run_0.jsonl'\n",
    "run = read_jsonl(general_annotations_file)\n",
    "\n",
    "ENTS_FROZEN = ['name_of_mof', 'mof_formula', 'mof_description', 'guest_species', 'applications']\n",
    "ent_scores_test = {e: [] for e in ENTS_FROZEN}\n",
    "ent_scores_gold = {e: [] for e in ENTS_FROZEN}\n",
    "\n",
    "exact_matches = 0\n",
    "unparsable = 0\n",
    "total = 0\n",
    "jaro_winkler_similarities = []\n",
    "\n",
    "LINK_DELIMITER = \"|||\"\n",
    "ROOT = (\"name_of_mof\",)\n",
    "\n",
    "ENTS_FROZEN_NOROOT = [e for e in ENTS_FROZEN if e not in ROOT]\n",
    "ENTS_LINKS_FROZEN = [f\"{root}{LINK_DELIMITER}{e}\" for e in ENTS_FROZEN_NOROOT for root in ROOT]\n",
    "\n",
    "subdict = {\"test_correct_triplets\": 0, \"test_retrieved_triplets\": 0, \"gold_retrieved_triplets\": 0}\n",
    "links_scores = {el: copy.deepcopy(subdict) for el in ENTS_LINKS_FROZEN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2290eed8-5178-44ba-867e-7d8d6e48533a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [{\"name_of_mof\": \"NH2-MIL-125\", \"mof_formula\": \"\", \"mof_description\": [\"amine-functionalized MOFs\"], \"guest_species\": [\"\"], \"applications\": [\"photocatalysis\", \"photocatalysts\"]}, {\"name_of_mof\": \"CdS/NH2-MIL-125@TiO2\", \"mof_formula\": \"\", \"mof_description\": [\"amine-functionalized MOFs\"], \"guest_species\": [\"\"], \"applications\": [\"photocatalysis\", \"photocatalysts\"]}]\\n\\nEND\\n\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run[0]['completion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ecd013b7-b71c-4fd2-b074-2f9ceabfccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ent_json_to_word_basis_sets(ent_json, return_empty=False):\n",
    "    \"\"\"\n",
    "    Where ent_json is multiple entries in a list\n",
    "\n",
    "    Return all entities and links in a set-based word basis\n",
    "    \"\"\"\n",
    "    # Must account for these in a weird way because the entries are not ordered :(\n",
    "    to_account = {e: set() for e in ENTS_FROZEN + ENTS_LINKS_FROZEN}\n",
    "\n",
    "    if return_empty:\n",
    "        return to_account\n",
    "\n",
    "    for entry in ent_json:\n",
    "        root_accounting = {root: set() for root in ROOT}\n",
    "        for etype in ENTS_FROZEN:\n",
    "            ent_strs = entry[etype]\n",
    "            if isinstance(ent_strs, str):\n",
    "                for w in ent_str_to_words(ent_strs):\n",
    "                    to_account[etype].add(w)\n",
    "                if etype in ROOT and ent_strs:\n",
    "                    # Formulae/roots must be counted as single words\n",
    "                    root_accounting[etype].add(ent_strs)\n",
    "                    # root_accounting[etype] = root_accounting[etype].union(set(ent_str_to_words(ent_strs)))\n",
    "            elif isinstance(ent_strs, list):\n",
    "                for ent_str in ent_strs:\n",
    "                    for w in ent_str_to_words(ent_str):\n",
    "                        to_account[etype].add(w)\n",
    "            else:\n",
    "                raise ValueError(f\"Ent strings was a weird type: {type(ent_strs)}, {ent_strs}\")\n",
    "\n",
    "        # Add links\n",
    "        for root, accounting in root_accounting.items():\n",
    "            if accounting:\n",
    "                for e in ENTS_FROZEN_NOROOT:\n",
    "                    ent_strs = entry[e]\n",
    "                    words = []\n",
    "                    if isinstance(ent_strs, str):\n",
    "                        words = ent_str_to_words(ent_strs)\n",
    "                    elif isinstance(ent_strs, list):\n",
    "                        for ent_str in ent_strs:\n",
    "                            words += ent_str_to_words(ent_str)\n",
    "                    else:\n",
    "                        raise ValueError(f\"Ent strings was a weird type: {type(ent_strs)}, {ent_strs}\")\n",
    "\n",
    "                    if words:\n",
    "                        for f in accounting:\n",
    "                            for w in words:\n",
    "                                # avoid self-links\n",
    "                                if f != w:\n",
    "                                    to_account[f\"{root}{LINK_DELIMITER}{e}\"].add(f\"{f}{LINK_DELIMITER}{w}\")\n",
    "    return to_account\n",
    "\n",
    "def check_equivalence_of_entries(gold_entry, test_entry):\n",
    "    ## Entries are a list of dictionaries\n",
    "    ## We first order each list, then each dictionary, then compare strings\n",
    "\n",
    "\n",
    "    ### order list by formula key\n",
    "    gold_entry = sorted(gold_entry, key=lambda x: x.get('formula', ''))\n",
    "    test_entry = sorted(test_entry, key=lambda x: x.get('formula', ''))\n",
    "\n",
    "    ### order each dictionary by keys\n",
    "    gold_entry = [dict(sorted(d.items())) for d in gold_entry]\n",
    "    test_entry = [dict(sorted(d.items())) for d in test_entry]\n",
    "\n",
    "    ### compare strings\n",
    "    return str(gold_entry) == str(test_entry)\n",
    "\n",
    "\n",
    "\n",
    "def ent_str_to_words(ent):\n",
    "    stripped =  [e.strip() for e in ent.split(\" \")]\n",
    "    return [e for e in stripped if e]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c49c7e07-d158-46a4-b004-e58e26bad5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                              | 0/51 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mJSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m jse:\n\u001b[0;32m     34\u001b[0m             unparsable \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcheck_equivalence_of_entries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgold_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_json\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     37\u001b[0m             exact_matches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     39\u001b[0m jws \u001b[38;5;241m=\u001b[39m jellyfish\u001b[38;5;241m.\u001b[39mjaro_winkler_similarity(gold_string, test_string, long_tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[38], line 63\u001b[0m, in \u001b[0;36mcheck_equivalence_of_entries\u001b[1;34m(gold_entry, test_entry)\u001b[0m\n\u001b[0;32m     60\u001b[0m test_entry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(test_entry, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformula\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m### order each dictionary by keys\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m gold_entry \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28msorted\u001b[39m(d\u001b[38;5;241m.\u001b[39mitems())) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m gold_entry]\n\u001b[0;32m     64\u001b[0m test_entry \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28msorted\u001b[39m(d\u001b[38;5;241m.\u001b[39mitems())) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m test_entry]\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m### compare strings\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[38], line 63\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     60\u001b[0m test_entry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(test_entry, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformula\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m### order each dictionary by keys\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m gold_entry \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m gold_entry]\n\u001b[0;32m     64\u001b[0m test_entry \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28msorted\u001b[39m(d\u001b[38;5;241m.\u001b[39mitems())) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m test_entry]\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m### compare strings\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "for sample in tqdm.tqdm(run):\n",
    "    gold_string = sample[\"completion\"].replace(\"\\n\\nEND\\n\\n\", \"\").strip()\n",
    "    test_string = sample[\"gpt3_completion\"].replace(\"\\n\\nEND\\n\\n\", \"\").replace('\\\\', '').strip()\n",
    "    # print(f\"Gold string is {gold_string}\")\n",
    "    # print(f\"Test string is {test_string}\")\n",
    "    gold_json = json.loads(gold_string)\n",
    "    prompt = sample[\"prompt\"].replace(\"\\n\\n###\\n\\n\", \"\").strip()\n",
    "    n_prompt_words = len([w for w in prompt.split(\" \") if w])\n",
    "    total += 1\n",
    "    test_json = {}\n",
    "    try:\n",
    "        test_json = sample[\"gpt3_completion\"]\n",
    "        if isinstance(test_json, str):\n",
    "            try:\n",
    "                test_json = json.loads(test_json)\n",
    "            except json.decoder.JSONDecodeError as jse:\n",
    "                test_json = []\n",
    "        for d in test_json:\n",
    "            for key in ENTS_FROZEN:\n",
    "                if key not in d:\n",
    "                    if key in [\"formula\", \"name\", \"acronym\", \"mof_formula\", \"name_of_mof\"]:\n",
    "                        d[key] = \"\"\n",
    "                    else:\n",
    "                        d[key] = [\"\"]\n",
    "\n",
    "            # remove extra keys as they are \"parsable\" but invalid\n",
    "            extra_keys = []\n",
    "            for key in d:\n",
    "                if key not in ENTS_FROZEN:\n",
    "                    extra_keys.append(key)\n",
    "            for key in extra_keys:\n",
    "                d.pop(key)\n",
    "    except json.decoder.JSONDecodeError as jse:\n",
    "                unparsable += 1\n",
    "\n",
    "    if check_equivalence_of_entries(gold_json, test_json):\n",
    "                exact_matches += 1\n",
    "\n",
    "    jws = jellyfish.jaro_winkler_similarity(gold_string, test_string, long_tolerance=True)\n",
    "    jaro_winkler_similarities.append(jws)\n",
    "\n",
    "    gold_accounting = ent_json_to_word_basis_sets(gold_json)\n",
    "\n",
    "    if test_json:\n",
    "        test_accounting = ent_json_to_word_basis_sets(test_json)\n",
    "    else:\n",
    "        test_accounting = ent_json_to_word_basis_sets({}, return_empty=True)\n",
    "    for etype in ENTS_FROZEN:\n",
    "        ent_accounting_copy = copy.deepcopy(test_accounting[etype])\n",
    "        n_unlabelled_words = copy.deepcopy(n_prompt_words)\n",
    "        for ew in gold_accounting[etype]:\n",
    "\n",
    "            # Account for true positives\n",
    "            if ew in test_accounting[etype]:\n",
    "                ent_scores_test[etype].append(1)\n",
    "                ent_scores_gold[etype].append(1)\n",
    "                ent_accounting_copy.remove(ew)\n",
    "                n_unlabelled_words -= 1\n",
    "            # account for false negatives\n",
    "            else:\n",
    "                ent_scores_test[etype].append(0)\n",
    "                ent_scores_gold[etype].append(1)\n",
    "                n_unlabelled_words -= 1\n",
    "\n",
    "        # Among the remaining test accounting words, only false positives\n",
    "        # should remain in the set\n",
    "        for ew in ent_accounting_copy:\n",
    "            ent_scores_test[etype].append(1)\n",
    "            ent_scores_gold[etype].append(0)\n",
    "            n_unlabelled_words -= 1\n",
    "\n",
    "        # the only labels remaining are true negatives\n",
    "        ent_scores_test[etype] += [0] * n_unlabelled_words\n",
    "        ent_scores_gold[etype] += [0] * n_unlabelled_words\n",
    "\n",
    "    for elinktype in ENTS_LINKS_FROZEN:\n",
    "        gold_triples = gold_accounting[elinktype]\n",
    "        test_triples = test_accounting[elinktype]\n",
    "\n",
    "        n_correct_triples = len([e for e in test_triples if e in gold_triples])\n",
    "        links_scores[elinktype][\"test_correct_triplets\"] += n_correct_triples\n",
    "        links_scores[elinktype][\"test_retrieved_triplets\"] += len(test_triples)\n",
    "        links_scores[elinktype][\"gold_retrieved_triplets\"] += len(gold_triples)\n",
    "    \n",
    "    break\n",
    "\n",
    "results = {\"ents\": {}, \"links\": {}}\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "for etype in ENTS_FROZEN:\n",
    "    gold_arr = ent_scores_gold[etype]\n",
    "    test_arr = ent_scores_test[etype]\n",
    "\n",
    "    subdict = {\"recall\": 0, \"precision\": 0, \"f1\": 0}\n",
    "    subdict[\"recall\"] = recall_score(gold_arr, test_arr)\n",
    "    subdict[\"precision\"] = precision_score(gold_arr, test_arr)\n",
    "    subdict[\"f1\"] = f1_score(gold_arr, test_arr)\n",
    "    results[\"ents\"][etype] = subdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6632131d-11a6-4de9-a1bc-dd0a85745008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name_of_mof': 'NH2-MIL-125',\n",
       "  'mof_formula': '',\n",
       "  'mof_description': ['amine-functionalized MOFs'],\n",
       "  'guest_species': [''],\n",
       "  'applications': ['photocatalysis', 'photocatalysts']},\n",
       " {'name_of_mof': 'CdS/NH2-MIL-125@TiO2',\n",
       "  'mof_formula': '',\n",
       "  'mof_description': ['amine-functionalized MOFs'],\n",
       "  'guest_species': [''],\n",
       "  'applications': ['photocatalysis', 'photocatalysts']}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f536dc55-60cf-46ad-b41d-f0dd223bec8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name_of_mof|||mof_formula': {'test_correct_triplets': 0,\n",
       "  'test_retrieved_triplets': 0,\n",
       "  'gold_retrieved_triplets': 0},\n",
       " 'name_of_mof|||mof_description': {'test_correct_triplets': 0,\n",
       "  'test_retrieved_triplets': 0,\n",
       "  'gold_retrieved_triplets': 0},\n",
       " 'name_of_mof|||guest_species': {'test_correct_triplets': 0,\n",
       "  'test_retrieved_triplets': 0,\n",
       "  'gold_retrieved_triplets': 0},\n",
       " 'name_of_mof|||applications': {'test_correct_triplets': 0,\n",
       "  'test_retrieved_triplets': 0,\n",
       "  'gold_retrieved_triplets': 0}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec4b7758-e59b-45a1-9459-aa9bb73cf5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [{\"acronym\": \"\", \"applications\": [\"\"], \"name\": \"post-perovskite\", \"formula\": \"MgSiO3\", \"structure_or_phase\": [\"\"], \"description\": [\"\"]}, {\"acronym\": \"\", \"applications\": [\"\"], \"name\": \"MgO\", \"formula\": \"\", \"structure_or_phase\": [\"CsCl\"], \"description\": [\"\"]}, {\"acronym\": \"\", \"applications\": [\"\"], \"name\": \"\", \"formula\": \"MgSi2O5\", \"structure_or_phase\": [\"P21/c\"], \"description\": [\"\"]}, {\"acronym\": \"\", \"applications\": [\"\"], \"name\": \"SiO2\", \"formula\": \"\", \"structure_or_phase\": [\"Fe2P\"], \"description\": [\"\"]}]\\n\\nEND\\n\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_answer = run[3]['completion']\n",
    "true_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d39c833e-8c53-4b3e-9e69-add50fdc9292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [{\"acronym\": \"\", \"applications\": [\"photovoltaics\", \"optoelectronics\"], \"name\": \"\", \"formula\": \"CH3NH3PbI3\", \"structure_or_phase\": [\"perovskite\"], \"description\": [\"single-crystalline\"]}]'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NERRE_answer = run[2]['gpt3_completion']\n",
    "NERRE_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4feaec56-905e-4a1a-abcf-b94e3360ed9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [{\"acronym\": \"\", \"applications\": [\"perovskite-based solar cells\", \"mesoporous scaffold\", \"solar cells\"], \"name\": \"\", \"formula\": \"Al2O3\", \"structure_or_phase\": [\"\"], \"description\": [\"nanostructured\"]}]\\n\\nEND\\n\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run[0]['completion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25f46752-fa80-4d2f-be96-7d2b3890c866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                             | 0/62 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for sample in tqdm(run):\n",
    "    gold_string = sample[\"completion\"].replace(\"\\n\\nEND\\n\\n\", \"\").strip()\n",
    "    test_string = sample[\"gpt3_completion\"].replace(\"\\n\\nEND\\n\\n\", \"\").replace('\\\\', '').strip()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "002fcc2a-ecd9-4130-a66b-3f4a4a8412be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"acronym\": \"\", \"applications\": [\"perovskite-based solar cells\", \"mesoporous scaffold\", \"solar cells\"], \"name\": \"\", \"formula\": \"Al2O3\", \"structure_or_phase\": [\"\"], \"description\": [\"nanostructured\"]}]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83771191-1e52-4f18-8891-fcfc28ed7f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function list.index(value, start=0, stop=9223372036854775807, /)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_names = list(eunomia.EunomiaTools.all_tools_dict.keys())\n",
    "vectorstore = \"../tests/test_files/test_vector_store.pkl\"\n",
    "a =eunomia.EunomiaTools(\n",
    "    tool_names=tool_names, vectorstore=vectorstore\n",
    "    ).get_tools()\n",
    "a.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc0b3b4-3a6e-4dc3-b165-fb83961516fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sensitivity enhancement in planar microwave active-resonator using metal organic framework for CO2 detection\\nThis work presents a proof of concepts of CO2 gas monitoring by a microwave sensor operating in microwave regime and study its sensitivity enhancement using an adsorbent bed of commercially available Zeolite 13X, and two synthesized MOF-199 (MOF-199-M1 and MOF-199-M2). The sensing principle of the sensor is based on the change in the dielectric properties of the bed, in response to CO2 concentration change in the dry CO2/He mixture. The sensor’s response is quantified in terms of change in the resonant frequency with respect to baseline for each material. The sensor shows maximum sensitivity of 24kHz/% CO2 for MOF-199-M2 and minimum of 10kHz/% CO2 for Zeolite 13 X. The sensitivity of the microwave senor to CO2 concentration, with MOF-199-M2 as the bed is higher than MOF-199-M1, which can be related to the presence of different amount of unsaturated Cu2+ ions in their frameworks. XPS and XRD studies revealed marginal structure difference between MOF-199-M1 and MOF-199-M2. MOF-199-M2 has higher adsorption capacity compared to Zeolite 13 X and MOF-199-M1 at CO2 concentration 45 vol.% which demonstrates potential application of microwave sensors even at high CO2 concentration (45 vol.%) using MOF-199-M2. Further work needs to study the sensor’s performance in non-dry gas streams at different levels of humidity and its integration with different materials to address the practical challenges, and to improve the selectivity of the sensor.\\n\\n###\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_inference[0]['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad5031e5-e00b-42c1-afbe-4353ca9c9b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [{\"name_of_mof\": \"MOF-1004\", \"mof_formula\": \"\", \"mof_description\": [\"\"], \"guest_species\": [\"\"], \"applications\": [\"\"]}, {\"name_of_mof\": \"MOF-1005\", \"mof_formula\": \"\", \"mof_description\": [\"\"], \"guest_species\": [\"\"], \"applications\": [\"\"]}, {\"name_of_mof\": \"MOF-177\", \"mof_formula\": \"\", \"mof_description\": [\"\"], \"guest_species\": [\"\"], \"applications\": [\"\"]}, {\"name_of_mof\": \"UiO-67\", \"mof_formula\": \"\", \"mof_description\": [\"\"], \"guest_species\": [\"\"], \"applications\": [\"\"]}]\\n\\nEND\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_inference[2]['completion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d8cc9b1-acfd-4c52-87a7-643e0281aa03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aabe6cd-9369-4ca8-b0bb-4339dee63074",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EunomiaTools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tools \u001b[38;5;241m=\u001b[39m \u001b[43mEunomiaTools\u001b[49m(tool_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_cif_from_COD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrename_cif\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mget_tools()\n\u001b[0;32m      4\u001b[0m agent \u001b[38;5;241m=\u001b[39m Eunomia(tools\u001b[38;5;241m=\u001b[39mtools, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m'\u001b[39m, get_cost\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m agent\u001b[38;5;241m.\u001b[39mrun(prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload cif files for this doi: 10.1021/cg301691d from COD and rename them.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EunomiaTools' is not defined"
     ]
    }
   ],
   "source": [
    "tools = EunomiaTools(tool_names = ['get_cif_from_COD', 'rename_cif']).get_tools()\n",
    "\n",
    "\n",
    "agent = Eunomia(tools=tools, model='gpt-4', get_cost=True)\n",
    "agent.run(prompt=\"Download cif files for this doi: 10.1021/cg301691d from COD and rename them.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "797a9b12-00f8-4cc5-b196-c6f70c8e6e07",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eunomia' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m paper_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m69\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m docs_processor \u001b[38;5;241m=\u001b[39m \u001b[43meunomia\u001b[49m\u001b[38;5;241m.\u001b[39mLoadDoc(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Data/chosen_papers/\u001b[39m\u001b[38;5;124m'\u001b[39m, paper_id\u001b[38;5;241m=\u001b[39mpaper_id)\n\u001b[0;32m      3\u001b[0m sliced_pages \u001b[38;5;241m=\u001b[39m docs_processor\u001b[38;5;241m.\u001b[39mprocess([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreferences \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macknowledgement\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macknowledgments\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreferences\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      4\u001b[0m                                              chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, chunking_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfixed-size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'eunomia' is not defined"
     ]
    }
   ],
   "source": [
    "paper_id = '69'\n",
    "docs_processor = eunomia.LoadDoc('../Data/chosen_papers/', paper_id=paper_id)\n",
    "sliced_pages = docs_processor.process(['references ', 'acknowledgement', 'acknowledgments', 'references\\n'],\n",
    "                                             chunk_size=1000, chunk_overlap=20, chunking_type='fixed-size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a03951d9-f0b1-44a7-a3e6-89bdfac27fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from typing import List, Optional\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class LoadDoc:\n",
    "    \"\"\"\n",
    "    A class to handle the loading and processing of different Docs.\n",
    "\n",
    "    Attributes:\n",
    "    paper_id : str\n",
    "        ID of the paper to be loaded.\n",
    "    paper_path : str\n",
    "        Path of the paper to be loaded.\n",
    "    loader : PyPDFLoader\n",
    "        Instance of PyPDFLoader to load the document.\n",
    "    pages : list\n",
    "        Pages of the loaded document.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filename: str = None, text_input: str = None, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        filename : str\n",
    "            Path to file.\n",
    "        text_input : str\n",
    "            Direct text input.\n",
    "        **kwargs are passed to the CSVLoader class.\n",
    "        \"\"\"\n",
    "        if filename is None and text_input is None:\n",
    "            raise ValueError(\"Either 'filename' or 'text_input' must be provided.\")\n",
    "        elif filename and text_input:\n",
    "            raise ValueError(\n",
    "                \"Only one of 'filename' or 'text_input' should be provided as input.\"\n",
    "            )\n",
    "\n",
    "        if filename:\n",
    "            extension = filename.split(\".\")[-1].lower()\n",
    "            self._check_extension(extension)\n",
    "            self.doc_path = filename\n",
    "            if self.type == \"pdf\":\n",
    "                from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "                self.loader = PyPDFLoader(filename)\n",
    "            if self.type == \"md\":\n",
    "                from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "                self.loader = UnstructuredMarkdownLoader(filename)\n",
    "            if self.type == \"csv\":\n",
    "                from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "                self.loader = CSVLoader(filename, **kwargs)\n",
    "            if self.type == \"txt\":\n",
    "                from langchain.document_loaders import TextLoader\n",
    "\n",
    "                self.loader = TextLoader(filename)\n",
    "            self.pages = self.loader.load_and_split()\n",
    "            print(type(self.pages))\n",
    "        else:\n",
    "            self.pages = [Document(page_content=text_input, metadata={\"source\": \"local\"})]\n",
    "\n",
    "    def _check_extension(self, extension: str):\n",
    "        \"\"\"\n",
    "        Checks the provided file extension against the supported extensions.\n",
    "\n",
    "        Parameters:\n",
    "        extension : str\n",
    "            File extension to check.\n",
    "\n",
    "        Raises:\n",
    "        Exception:\n",
    "            If the file extension is not supported.\n",
    "        NotImplementedError:\n",
    "            If the file extension is 'xml', which is not yet implemented.\n",
    "        \"\"\"\n",
    "        supported_extensions = {\"pdf\", \"txt\", \"md\", \"csv\"}\n",
    "        if extension in supported_extensions:\n",
    "            self.type = extension\n",
    "        elif extension == \"xml\":\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            raise Exception(f\"Eunomia supports {supported_extensions} doc files.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def cut_text(text: str, keywords: List[str]) -> str:\n",
    "        \"\"\"\n",
    "        Cuts the given text up to the first found keyword.\n",
    "\n",
    "        Parameters:\n",
    "        text : str\n",
    "            The text to be cut.\n",
    "        keywords : List[str]\n",
    "            List of keywords to find in the text.\n",
    "\n",
    "        Returns:\n",
    "        str\n",
    "            The cut text.\n",
    "        \"\"\"\n",
    "        lower_text = text.lower()\n",
    "        indices = [\n",
    "            lower_text.find(keyword)\n",
    "            for keyword in keywords\n",
    "            if lower_text.find(keyword) != -1\n",
    "        ]\n",
    "        min_index = min(indices)\n",
    "        return text[:min_index].strip()  # remove any trailing spaces\n",
    "\n",
    "    @staticmethod\n",
    "    def find_in_document(document: Document, search_strings: List[str]) -> bool:\n",
    "        \"\"\"\n",
    "        Searches for the given strings in the document content.\n",
    "\n",
    "        Parameters:\n",
    "        document : Document\n",
    "            Document in which to search.\n",
    "        search_strings : List[str]\n",
    "            List of strings to search for.\n",
    "\n",
    "        Returns:\n",
    "        bool\n",
    "            True if any of the search strings are found, False otherwise.\n",
    "        \"\"\"\n",
    "        return any(\n",
    "            search_string.lower() in document.page_content.lower()\n",
    "            for search_string in search_strings\n",
    "        )\n",
    "\n",
    "    def filter_documents(\n",
    "        self, documents: List[Document], search_strings: List[str]\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Filters documents based on the presence of search strings.\n",
    "        use this if you wish to remove \"Acknowledgments or \"References\"\n",
    "        in a long research article.\n",
    "\n",
    "        Parameters:\n",
    "        documents : List[Document]\n",
    "            List of documents to filter.\n",
    "        search_strings : List[str]\n",
    "            List of strings to search for.\n",
    "\n",
    "        Returns:\n",
    "        List[Document]\n",
    "            List of filtered documents.\n",
    "        \"\"\"\n",
    "        filtered_documents = deepcopy(documents)  # Create a deep copy of documents\n",
    "        for i, doc in enumerate(filtered_documents):\n",
    "            if self.find_in_document(doc, search_strings):\n",
    "                filtered_documents[i].page_content = self.cut_text(\n",
    "                    filtered_documents[i].page_content,\n",
    "                    keywords=search_strings,\n",
    "                )\n",
    "                filtered_documents = filtered_documents[: i + 1]\n",
    "                break\n",
    "        return filtered_documents\n",
    "\n",
    "    def process(\n",
    "        self,\n",
    "        filter_words: List[str] = [],\n",
    "        chunk_size: Optional[int] = None,\n",
    "        chunk_overlap: Optional[int] = 0,\n",
    "        chunking_type=\"fixed-size\",\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Process the document pages based on the search strings. Additionally, this function\n",
    "        will split the document into chunks if a chunk size is provided.\n",
    "\n",
    "        Parameters:\n",
    "        filter_words : List[str]\n",
    "            List of words to search and filter.\n",
    "        chunk_size : Optional[int]\n",
    "            The size of the chunks in which the document will be split. If this parameter\n",
    "            is not provided, the document will not be split into chunks.\n",
    "        chunk_overlap : Optional[int]\n",
    "            The size of the overlap between chunks. If chunk_size is not provided, this\n",
    "            parameter will not be used.\n",
    "\n",
    "        Returns:\n",
    "        List[Document]\n",
    "            List of processed document chunks.\n",
    "        \"\"\"\n",
    "        sliced_pages = self.filter_documents(self.pages, filter_words)\n",
    "        text_splitter = None\n",
    "        if chunk_size is not None:\n",
    "            if chunking_type == \"fixed-size\":\n",
    "                from langchain.text_splitter import (\n",
    "                    CharacterTextSplitter,\n",
    "                )\n",
    "\n",
    "                text_splitter = CharacterTextSplitter(\n",
    "                    chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    "                )\n",
    "            if chunking_type == \"latex\":\n",
    "                from langchain.text_splitter import LatexTextSplitter\n",
    "\n",
    "                text_splitter = LatexTextSplitter(\n",
    "                    chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    "                )\n",
    "            if chunking_type == \"NLTK\":\n",
    "                from langchain.text_splitter import NLTKTextSplitter\n",
    "\n",
    "                text_splitter = NLTKTextSplitter(\n",
    "                    chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    "                )\n",
    "            if chunking_type == \"spacy\":\n",
    "                from langchain.text_splitter import SpacyTextSplitter\n",
    "\n",
    "                text_splitter = SpacyTextSplitter(\n",
    "                    chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    "                )\n",
    "\n",
    "            sliced_pages = text_splitter.split_documents(sliced_pages)\n",
    "\n",
    "        return sliced_pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75089b1c-da68-4485-9987-31ee640207b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['name:', 'description:']\n",
      "<class 'list'>\n",
      "['thermospheric', 'models.']\n",
      "<class 'list'>\n",
      "['Mehrad', 'Ansari.']\n",
      "<class 'list'>\n",
      "['bioRxiv', 'preprint']\n"
     ]
    }
   ],
   "source": [
    "import eunomia\n",
    "extensions = [\"csv\", \"txt\", \"md\", \"pdf\"]\n",
    "test_results = [['name:', 'description:'], ['thermospheric', 'models.'], ['Mehrad', 'Ansari.'], ['bioRxiv', 'preprint']]\n",
    "\n",
    "for e in extensions:\n",
    "    test_file_name = f\"../tests/test_files/test_docs.{e}\"\n",
    "    docs_processor = eunomia.LoadDoc(file_name=test_file_name)\n",
    "    doc_pages = docs_processor.process(\n",
    "        filter_words=[\n",
    "            \"references \",\n",
    "            \"acknowledgement\",\n",
    "            \"acknowledgments\",\n",
    "            \"references\\n\",\n",
    "        ],\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=20,\n",
    "        chunking_type=\"fixed-size\",\n",
    "    )\n",
    "    print(doc_pages[-1].page_content.split()[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f9ac49f-260b-4787-9420-f5aac3b4fe66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bioRxiv', 'preprint']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7150f805-3a7e-4536-bc98-ad35af24ccf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thermospheric', 'models.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_input = \"Electrodynamics in superconductors explained by Proca equations\\nA fully consistent model to study electrodynamics for superconductors in the stationary and non-stationary regimes has been developed based on Proca equations and a massive photon. In particular, this approach has been applied to study the electric field penetration depth in superconductors. The model shows a deviation from the charge contribution to an internal electric field compared to previous approaches\"\n",
    "\n",
    "with open(\"../tests/test_files/test_docs.txt\", \"rb\") as f:\n",
    "    text_input = f.read()\n",
    "\n",
    "docs_processor = LoadDoc(text_input=text_input)\n",
    "sliced_pages = docs_processor.process(filter_words=['references ', 'acknowledgement', 'acknowledgments', 'references\\n'],\n",
    "                                             chunk_size=1000, chunk_overlap=20, chunking_type='fixed-size')\n",
    "sliced_pages[-1].page_content.split()[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d83200b2-8b12-4f08-8c83-dcf2951cb366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1005, which is longer than the specified 1000\n",
      "Created a chunk of size 1004, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import eunomia\n",
    "paper_file = '../Data/chosen_papers/1.pdf'\n",
    "# filename = 'OutdoorClothingCatalog_1000.csv'\n",
    "docs_processor = LoadDoc(filename=filename, encoding=\"utf8\")\n",
    "sliced_pages = docs_processor.process(filter_words=['references ', 'acknowledgement', 'acknowledgments', 'references\\n'],\n",
    "                                             chunk_size=1000, chunk_overlap=20, chunking_type='fixed-size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1851eee5-831a-4777-8889-f32c33815e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "loader = TextLoader(\"sample_text.txt\")\n",
    "doc =  Document(page_content=\"text\", metadata={\"source\": \"local\"})\n",
    "a = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1dc485fa-94eb-4d98-94e7-0d9198424237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.schema.document.Document"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e613b5d9-474d-4442-9079-6734b6c785c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.schema.document.Document"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb51fae-0bee-4b48-b957-45b90479886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "Embedding_model = 'text-embedding-ada-002' # text-embedding-ada-002 text-davinci-003\n",
    "faiss_index_path = f\"../Data/chosen_papers/faiss/{Embedding_model}/faiss_index_{Embedding_model}_{paper_id}.pkl\"\n",
    "faiss_index = FAISS.from_documents(sliced_pages, OpenAIEmbeddings(model=Embedding_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44bff732-bfdb-4dd2-8fdc-42e6430c5b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Effect of ceria structural properties on the catalytic activity of Au–CeO2 catalysts for WGS reaction\\nTwo gold based catalysts supported on ceria prepared by different methods (urea gelation coprecipitation, UGC, and coprecipitation, CP) have been synthesized and tested in the WGS reaction, showing quite different catalytic behaviors. Interestingly, the two catalysts have the same gold loading (3 wt% Au was inserted by deposition–precipitation) and the FTIR spectroscopy of the adsorbed CO revealed the same amount of gold exposed sites. With the aim to elucidate how the preparation method affects the properties of the support, a morphological, structural and textural characterization has been performed by HRTEM, XRD, BET and Raman analyses, as well as FTIR spectroscopy to probe both the Au and the support exposed sites. It was found that the UGC method gave rise to an enhancement of the defectivity of ceria and to an increase of the reactivity under reductive treatment. Further FTIR measurements of adsorbed acetone demonstrated the presence of two kinds of Ce4+ sites with different coordination, (CUS) Ce4+ A and (CUS) Ce4+ B, on the UGC sample. Such sites can influence the catalytic activity, possibly favoring the water dissociation, making ceria prepared by UGC a better support for Au catalysts than the CP-prepared one.\\n\\n###\\n\\n',\n",
       " 'completion': ' [{\"acronym\": \"\", \"applications\": [\"catalyst\", \"WGS reaction\"], \"name\": \"gold\", \"formula\": \"Au\", \"structure_or_phase\": [\"\"], \"description\": [\"supported on ceria\"]}, {\"acronym\": \"\", \"applications\": [\"catalyst\", \"WGS reaction\"], \"name\": \"ceria\", \"formula\": \"\", \"structure_or_phase\": [\"\"], \"description\": [\"\"]}]\\n\\nEND\\n\\n'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with open('../data/NERRE/general_materials_information_annotations.jsonl', 'rb') as f:\n",
    "    for line in f:\n",
    "        general_annotations = json.loads(line)\n",
    "\n",
    "general_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c2dc558-82c2-45a9-b52f-48276d75123e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['prompt', 'completion'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_annotations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba13ff07-3136-40e5-b125-f5929e26acb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
