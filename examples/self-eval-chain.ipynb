{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "515627c3-c1e4-470f-b7a0-c70e08f05325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b3d1b9-a6c5-4039-b3bd-b5e46920dfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehra\\anaconda3\\envs\\agent\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import eunomia\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e8a4516-dd97-40bf-a7e0-7edafb5cf02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_id = '1'\n",
    "docs_processor = eunomia.LoadDoc('../Data/SI_PDF/', paper_id=paper_id)\n",
    "sliced_pages = docs_processor.process(['references ', 'acknowledgement', 'acknowledgments', 'references\\n'],\n",
    "                                             chunk_size=1000, chunk_overlap=10, chunking_type='fixed-size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afdb9e14-d7b4-4582-a90b-1764c4355010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadded Embeddings\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "k = 5\n",
    "# Embedding_model = 'text-davinci-003' # text-embedding-ada-002\n",
    "Embedding_model = 'text-embedding-ada-002' # text-embedding-ada-002\n",
    "\n",
    "\n",
    "faiss_index_path = f\"../Data/chosen_papers/faiss/{Embedding_model}/faiss_index_{Embedding_model}_{paper_id}.pkl\"\n",
    "just_load = True\n",
    "if os.path.isfile(faiss_index_path) and just_load:\n",
    "    print('loadded Embeddings')\n",
    "    with open(faiss_index_path, \"rb\") as f:\n",
    "        faiss_index = pickle.load(f)\n",
    "else:\n",
    "    with open(faiss_index_path, \"wb\") as f:  # text-embedding-ada-002\n",
    "        faiss_index = FAISS.from_documents(sliced_pages, OpenAIEmbeddings(model=Embedding_model))    # 'text-davinci-003\n",
    "        pickle.dump(faiss_index, f)\n",
    "\n",
    "# faiss_index = LanceDB.from_documents(sliced_pages, OpenAIEmbeddings(model=Embedding_model))\n",
    "\n",
    "retriever  = faiss_index.as_retriever(search_type=\"mmr\", search_kwargs={\"k\":k, 'fetch_k': 50}) # Maximum Marginal Relevance Retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7189afd-8c23-4c9c-9c1a-0ebe3682381b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehra\\anaconda3\\envs\\agent\\lib\\site-packages\\langchain\\llms\\openai.py:201: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "C:\\Users\\mehra\\anaconda3\\envs\\agent\\lib\\site-packages\\langchain\\llms\\openai.py:786: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import Tool, tool\n",
    "from langchain.chat_models  import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "llm = OpenAI(temperature=0, model_name='gpt-3.5-turbo-16k') # gpt-3.5-turbo-16k\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09f6c002-273d-40a4-9dfa-188de396063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rule = f\"\"\"\n",
    "There are only 3 options for water stability: \\\n",
    "1. Stable \\\n",
    "2. Unstable \\\n",
    "3. Not provided\\\n",
    "For 1. Stable, \\\n",
    "No change after exposure, soaking or boiling in water or an aqueous solution.\\\n",
    "Water adsorption isotherm should have a steep uptake.\\\n",
    "For 2. Unstable, \\\n",
    "The MOF will decompose after exposure \\\n",
    "to humid environment or partially dissolves in water. \\\n",
    "For 3. Not provided, \\\n",
    "If you don't know or cannot justfy 1 or 2\n",
    "\"\"\"\n",
    "\n",
    "# Steep uptake behavior is from this paper: https://pubs.acs.org/doi/epdf/10.1021/ja306812r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5608e46-c498-49b1-9601-3ac3b4508252",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3a = f\"\"\"\n",
    "    You are an expert chemist. The doc tool describes the water stability properties of a few materials including \\\n",
    "    Metal-Organic Frameworks(MOF) or coordination polymers, Coordination Networks or ZIF compounds. Please find \\\n",
    "    the full name for materials, and their \\\n",
    "    stability in water. \\\n",
    "    Your final answer should contain the following:\\\n",
    "    Your first output is the water stability of each MOF. \\\n",
    "    Your second output for each mof should be a probability score ranging between [0, 1].\\\n",
    "    This probability score shows how certain you are in your answer.\\\n",
    "    Your third output should be exact sentences without any changes from the document that justifies your decision.\\\n",
    "    This should be \"Not provided\" if you cannot find water stability.\\\n",
    "    Rule: {Rule}\\\n",
    "    If there are multiple MOFs, please list them all and put \"MOF name\" before them. \\\n",
    "    You should only respond in JSON format as described below. \n",
    "    Make sure it is parsable using Python json.load.\n",
    "    Make sure \"MOF name\"s do not have duplicates\n",
    "    If information is not provided, state it as not provided.\\\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9f08740-70f1-44a3-a876-3145fee0d52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"MOF-11\": {\\n    \"water_stability\": \"Unstable\",\\n    \"probability_score\": 1,\\n    \"justification\": \"Bio-MOF-11 dissolved rapidly in water, as evidenced by PXRD (Fig. 10); SEM images could not be obtained.\"\\n  },\\n  \"MOF-12\": {\\n    \"water_stability\": \"Unstable\",\\n    \"probability_score\": 1,\\n    \"justification\": \"Bio-MOF-12 dissolved partially in water. The intensity of their signature diﬀraction lines decreased substantially (Fig. 10); SEM images of the soaked samples revealed significant crystallite fragmentation and pitting of the crystal surfaces (Fig. S21 †).\"\\n  },\\n  \"MOF-13\": {\\n    \"water_stability\": \"Unstable\",\\n    \"probability_score\": 1,\\n    \"justification\": \"Bio-MOF-13 dissolved partially in water. The intensity of their signature diﬀraction lines decreased substantially (Fig. 10); SEM images of the soaked samples revealed significant crystallite fragmentation and pitting of the crystal surfaces (Fig. S21 †).\"\\n  },\\n  \"MOF-14\": {\\n    \"water_stability\": \"Stable\",\\n    \"probability_score\": 1,\\n    \"justification\": \"Bio-MOF-14 showed no loss of crystallinity and no significant crystal degradation after soaking in water for 1 hour (Fig. 11). CO2 isotherms collected after extended exposure to water showed no loss in crystallinity and closely matched the isotherm of the non-water-treated sample, indicating that water does not affect the porosity of the material (Fig. 12).\"\\n  }\\n}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "qa.run(prompt3a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df9faeeb-724e-4c4d-b672-a44d36336e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def read_context(input):\n",
    "    '''\n",
    "    use this as the primary source of context information when you are asked the input.\n",
    "    Always search for the answers using this tool first, don't make up answers yourself\n",
    "    '''\n",
    "    llm = OpenAI(temperature=0, model_name='gpt-3.5-turbo-16k') # gpt-3.5-turbo-16k\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "    return qa_chain({\"query\": input})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f452ec93-15c0-4ae7-9a26-f489fbeb3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "read_context_tool = create_retriever_tool(\n",
    "    retriever, \n",
    "    \"Read_paper\",\n",
    "    \"Use this as the primary source of context information when you are asked the question about MOFs. Always search for the answers using this tool first, don't make up answers yourself\"\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    # Tool(\n",
    "    #     name = \"Read_paper\",\n",
    "    #     func=qa.run,\n",
    "    #     description=f\"Useful for when you need to answer questions about MOFs.\"\n",
    "    # )]\n",
    "    read_context_tool]\n",
    "    #eval_justification]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac7a5097-27ab-4ce2-a92d-7e51f9e27e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.agents.agent_toolkits import create_conversational_retrieval_agent\n",
    "# agent_executor = create_conversational_retrieval_agent(llm, tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "577e186b-9842-4dca-93f5-be3fe774b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with get_openai_callback() as cb:\n",
    "#     agent_executor(prompt3a)\n",
    "#     print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6380a3c5-3c2b-4998-ae42-ea0ac68fd33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name = \"doc\",\n",
    "        func=qa.run,\n",
    "        description=f\"Always use this tool for context. Use the original prompt for this tool to get context about water stability of MOFs.\"\n",
    "    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b80b5d52-5539-4917-83c8-18d9a6f5e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa.run(prompt3a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "87c93d70-4c9d-4b10-b26a-fb1547c9eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import GPTListIndex, GPTIndexMemory\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "# index = GPTListIndex([])\n",
    "# memory = GPTIndexMemory(index=GPTListIndex([]), memory_key=\"chat_history\", query_kwargs={\"response_mode\": \"compact\"})\n",
    "agent_llm = OpenAI(temperature=0, model_name='gpt-3.5-turbo-16k')\n",
    "agent_chain = initialize_agent(tools, agent_llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                               verbose=True, memory=None, handle_parsing_errors=True,\n",
    "                              prefix= prompt3a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f330cacc-715b-449b-93f2-b425ac4c204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to use the doc tool to find the water stability properties of MOFs.\n",
      "Action: doc\n",
      "Action Input: water stability of MOFs\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mBased on the information provided, the water stability of the bio-MOFs was evaluated by soaking them in water for different periods of time and then evaluating their stability using PXRD and SEM imaging. Bio-MOF-11 dissolved rapidly in water, while bio-MOFs-12 and 13 dissolved partially. Bio-MOF-13, with butyrate, was noticeably more stable in water than bio-MOF-12, with propionate. Bio-MOF-14, with valerate groups, was the most stable and showed no loss of crystallinity or significant crystal degradation after soaking in water for 1 hour, 7 days, or 30 days. Additionally, CO2 isotherms collected for bio-MOF-14 soaked in water for 7 or 30 days showed no loss in crystallinity and closely matched the isotherm of the non-water-treated sample, indicating that water did not affect the porosity of the material.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found the water stability properties of some MOFs from the document.\n",
      "Action: doc\n",
      "Action Input: MOF stability in water\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mBased on the information provided, it can be concluded that the water stability of the bio-MOFs is influenced by the identity of the aliphatic group. Bio-MOF-11 dissolved rapidly in water, while bio-MOFs-12 and 13 dissolved partially. Bio-MOF-13, with butyrate, was noticeably more stable in water than bio-MOF-12, with propionate. Bio-MOF-14, with valerate groups, was the most stable and showed no loss of crystallinity or significant crystal degradation after soaking in water for 1 hour, 7 days, or 30 days.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have gathered all the necessary information about the water stability of MOFs.\n",
      "Final Answer: \n",
      "{\n",
      "  \"MOF name\": \"bio-MOF-11\",\n",
      "  \"Water Stability\": \"Unstable\",\n",
      "  \"Probability Score\": 1,\n",
      "  \"Justification\": \"Bio-MOF-11 dissolved rapidly in water.\"\n",
      "},\n",
      "{\n",
      "  \"MOF name\": \"bio-MOF-12\",\n",
      "  \"Water Stability\": \"Unstable\",\n",
      "  \"Probability Score\": 1,\n",
      "  \"Justification\": \"Bio-MOF-12 dissolved partially in water.\"\n",
      "},\n",
      "{\n",
      "  \"MOF name\": \"bio-MOF-13\",\n",
      "  \"Water Stability\": \"Unstable\",\n",
      "  \"Probability Score\": 1,\n",
      "  \"Justification\": \"Bio-MOF-13 dissolved partially in water.\"\n",
      "},\n",
      "{\n",
      "  \"MOF name\": \"bio-MOF-14\",\n",
      "  \"Water Stability\": \"Stable\",\n",
      "  \"Probability Score\": 1,\n",
      "  \"Justification\": \"Bio-MOF-14 showed no loss of crystallinity or significant crystal degradation after soaking in water for 1 hour, 7 days, or 30 days.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Tokens Used: 9523\n",
      "\tPrompt Tokens: 8915\n",
      "\tCompletion Tokens: 608\n",
      "Successful Requests: 5\n",
      "Total Cost (USD): $0.029177000000000005\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = agent_chain.run(prompt3a)\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b679d213-f31c-45ce-98c9-7592feb2bdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"MOF name\": \"bio-MOF-11\",\\n  \"Water Stability\": \"Unstable\",\\n  \"Probability Score\": 1,\\n  \"Justification\": \"Bio-MOF-11 dissolved rapidly in water.\"\\n},\\n{\\n  \"MOF name\": \"bio-MOF-12\",\\n  \"Water Stability\": \"Unstable\",\\n  \"Probability Score\": 1,\\n  \"Justification\": \"Bio-MOF-12 dissolved partially in water.\"\\n},\\n{\\n  \"MOF name\": \"bio-MOF-13\",\\n  \"Water Stability\": \"Unstable\",\\n  \"Probability Score\": 1,\\n  \"Justification\": \"Bio-MOF-13 dissolved partially in water.\"\\n},\\n{\\n  \"MOF name\": \"bio-MOF-14\",\\n  \"Water Stability\": \"Stable\",\\n  \"Probability Score\": 1,\\n  \"Justification\": \"Bio-MOF-14 showed no loss of crystallinity or significant crystal degradation after soaking in water for 1 hour, 7 days, or 30 days.\"\\n}'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "15f28e0e-e414-42f5-95b6-7d24793f8108",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain.agents import AgentOutputParser\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish, OutputParserException\n",
    "\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        '''\n",
    "        Use this tool last to parse the final answer to a dictionary.\n",
    "        '''\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            print('FUCK')\n",
    "            from typing import List\n",
    "            from pydantic import BaseModel, Field, validator\n",
    "            from langchain.output_parsers import OutputFixingParser, PydanticOutputParser\n",
    "    \n",
    "            class MOF(BaseModel):\n",
    "                name: str = Field(description=\"name of a MOF\")\n",
    "                stability: str = Field(description=\"choose only one: stable or unstable or not provided\")\n",
    "                score: float = Field(description=\"probability score of prediction\")\n",
    "                justification: str = Field(description=\"justification for prediction\")\n",
    "        \n",
    "            class MOFList(BaseModel):\n",
    "                MOFs: List[MOF]\n",
    "        \n",
    "            parser = PydanticOutputParser(pydantic_object=MOFList)\n",
    "            llm_parser = OutputFixingParser.from_llm(parser=parser, llm=ChatOpenAI(temperature=0))\n",
    "        \n",
    "            try:\n",
    "                parsed_result = llm_parser.parse(llm_output)\n",
    "            except ValueError as e:\n",
    "                raise ValueError(f\"Failed to parse MOF: {e}\")\n",
    "        \n",
    "            dict_response = {mof.name: {\"Predicted Stability\": mof.stability, \"Score\": mof.score, \"Justification\": mof.justification} for mof in parsed_result.MOFs}\n",
    "            new_dict = {key: {**value} for key, value in dict_response.items()}\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": new_dict},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise OutputParserException(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
    "\n",
    "output_parser = CustomOutputParser()\n",
    "    # def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "    #     # Check if agent should finish\n",
    "    #     if \"Final Answer:\" in llm_output:\n",
    "    #         return AgentFinish(\n",
    "    #             # Return values is generally always a dictionary with a single `output` key\n",
    "    #             # It is not recommended to try anything else at the moment :)\n",
    "    #             return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "    #             log=llm_output,\n",
    "    #         )\n",
    "    #     # Parse out the action and action input\n",
    "    #     regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "    #     match = re.search(regex, llm_output, re.DOTALL)\n",
    "    #     if not match:\n",
    "    #         raise OutputParserException(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "    #     action = match.group(1).strip()\n",
    "    #     action_input = match.group(2)\n",
    "    #     # Return the action and action input\n",
    "    #     return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3f0a7a4e-2a45-49e1-9129-596c10922aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "mof_name_schema = ResponseSchema(name=\"MOF_name\",\n",
    "                             description=\"This is the name of the MOF\")\n",
    "\n",
    "water_stability_schema = ResponseSchema(name=\"water_stability\",\n",
    "                                      description=\"This is the stability of the MOF: Stable, Unstable or Not provided\")\n",
    "\n",
    "probability_score_schema = ResponseSchema(name=\"probability_score\",\n",
    "                                      description=\"This is an integer score between 1-10\")\n",
    "\n",
    "justification_schema = ResponseSchema(name=\"justification\",\n",
    "                                    description=\"This is sentense that justifies the predicted water stability.\")\n",
    "\n",
    "response_schemas = [mof_name_schema, \n",
    "                    water_stability_schema,\n",
    "                    probability_score_schema,\n",
    "                    justification_schema]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "36ba9b12-70e1-4caa-8d3a-86ee3ea96f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6d679670-ea64-4ae7-8438-155d8a9d53b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to use the doc tool to find information about the water stability of MOFs. I should also keep track of the sentences that justify my decision.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to use the doc tool to find information about the water stability of MOFs. I should also keep track of the sentences that justify my decision.\n",
      "Action: doc\n",
      "Action Input: water stability of MOFs\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mBased on the information provided, the water stability of the bio-MOFs was evaluated by soaking them in water for different periods of time and then evaluating their stability using PXRD and SEM imaging. Bio-MOF-11 dissolved rapidly in water, while bio-MOFs-12 and 13 dissolved partially. Bio-MOF-13, with butyrate, was noticeably more stable in water than bio-MOF-12, with propionate. Bio-MOF-14, with valerate groups, was the most stable and showed no loss of crystallinity or significant crystal degradation after soaking in water for 1 hour, 7 days, or 30 days. Additionally, CO2 isotherms collected for bio-MOF-14 soaked in water for 7 or 30 days showed no loss in crystallinity and closely matched the isotherm of the non-water-treated sample, indicating that water did not affect the porosity of the material.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found information about the water stability of MOFs in the document. I should now use the eval_justification tool to check if the sentences justify the water stability.\n",
      "Action: eval_justification\n",
      "Action Input: Based on the information provided, the water stability of the bio-MOFs was evaluated by soaking them in water for different periods of time and then evaluating their stability using PXRD and SEM imaging. Bio-MOF-11 dissolved rapidly in water, while bio-MOFs-12 and 13 dissolved partially. Bio-MOF-13, with butyrate, was noticeably more stable in water than bio-MOF-12, with propionate. Bio-MOF-14, with valerate groups, was the most stable and showed no loss of crystallinity or significant crystal degradation after soaking in water for 1 hour, 7 days, or 30 days. Additionally, CO2 isotherms collected for bio-MOF-14 soaked in water for 7 or 30 days showed no loss in crystallinity and closely matched the isotherm of the non-water-treated sample, indicating that water did not affect the porosity of the material.\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mYes, the sentence accurately describes information on water stability on all found MOFs. It provides specific details about the water stability of different bio-MOFs and their behavior when soaked in water for different periods of time. It also mentions the evaluation methods used (PXRD and SEM imaging) and the results obtained for each bio-MOF. Additionally, it discusses the porosity of the material and how water did not affect it.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: {\"MOF name\": \"bio-MOF-11\", \"Water Stability\": \"Unstable\", \"Probability Score\": 1, \"Justification\": \"Based on the information provided, the water stability of the bio-MOFs was evaluated by soaking them in water for different periods of time and then evaluating their stability using PXRD and SEM imaging. Bio-MOF-11 dissolved rapidly in water.\"}, {\"MOF name\": \"bio-MOF-12\", \"Water Stability\": \"Unstable\", \"Probability Score\": 1, \"Justification\": \"Based on the information provided, the water stability of the bio-MOFs was evaluated by soaking them in water for different periods of time and then evaluating their stability using PXRD and SEM imaging. Bio-MOFs-12 dissolved partially in water.\"}, {\"MOF name\": \"bio-MOF-13\", \"Water Stability\": \"Unstable\", \"Probability Score\": 1, \"Justification\": \"Based on the information provided, the water stability of the bio-MOFs was evaluated by soaking them in water for different periods of time and then evaluating their stability using PXRD and SEM imaging. Bio-MOF-13 dissolved partially in water.\"}, {\"MOF name\": \"bio-MOF-14\", \"Water Stability\": \"Stable\", \"Probability Score\": 1, \"Justification\": \"Based on the information provided, the water stability of the bio-MOFs was evaluated by soaking them in water for different periods of time and then evaluating their stability using PXRD and SEM imaging. Bio-MOF-14 showed no loss of crystallinity or significant crystal degradation after soaking in water for 1 hour, 7 days, or 30 days. Additionally, CO2 isotherms collected for bio-MOF-14 soaked in water for 7 or 30 days showed no loss in crystallinity and closely matched the isotherm of the non-water-treated sample, indicating that water did not affect the porosity of the material.\"}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Tokens Used: 7450\n",
      "\tPrompt Tokens: 6530\n",
      "\tCompletion Tokens: 920\n",
      "Successful Requests: 5\n",
      "Total Cost (USD): $0.023270000000000006\n"
     ]
    }
   ],
   "source": [
    "prompt3a = f\"\"\"\n",
    "    You are an expert chemist. The doc tool describes the water stability properties of a few materials including \\\n",
    "    Metal-Organic Frameworks(MOF) or coordination polymers, Coordination Networks or ZIF compounds. Please find \\\n",
    "    the full name for materials, and their \\\n",
    "    stability in water. \\\n",
    "    Your final answer should contain the following:\\\n",
    "    Your first output is the water stability of each MOF. \\\n",
    "    Your second output for each mof should be a probability score ranging between [0, 1].\\\n",
    "    This probability score shows how certain you are in your answer.\\\n",
    "    Your third output should be exact sentences without any changes from the document that justifies your decision.\\\n",
    "    This should be \"Not provided\" if you cannot find water stability.\\\n",
    "    Rule: {Rule}\\\n",
    "    If there are multiple MOFs, please list them all and put \"MOF name\" before them. \\\n",
    "    You should only respond in JSON format as described below. \n",
    "    Make sure it is parsable using Python json.load.\n",
    "    Make sure \"MOF name\"s do not have duplicates\n",
    "    If information is not provided, state it as not provided.\\\n",
    "    \"\"\"\n",
    "    \n",
    "#     \"\"\"\n",
    "\n",
    "Rule = f\"\"\"\n",
    "There are only 3 options for water stability: \\\n",
    "1. Stable \\\n",
    "2. Unstable \\\n",
    "3. Not provided\\\n",
    "For 1. Stable, \\\n",
    "No change after exposure, soaking or boiling in water or an aqueous solution.\\\n",
    "Water adsorption isotherm should have a steep uptake.\\\n",
    "For 2. Unstable, \\\n",
    "The MOF will decompose after exposure \\\n",
    "to humid environment or partially dissolves in water. \\\n",
    "For 3. Not provided, \\\n",
    "If you don't know or cannot justfy 1 or 2\n",
    "\"\"\"\n",
    "\n",
    "@tool\n",
    "def doc_retrival(input):\n",
    "    \"\"\"Use this as the primary source of context information when you are asked the question about MOFs.\n",
    "    Always search for the answers using this tool first, don't make up answers yourself\"\"\"\n",
    "    paper_id = '1'\n",
    "    docs_processor = eunomia.LoadDoc('../Data/SI_PDF/', paper_id=paper_id)\n",
    "    sliced_pages = docs_processor.process(['references ', 'acknowledgement', 'acknowledgments', 'references\\n'],\n",
    "                                                 chunk_size=1000, chunk_overlap=10, chunking_type='fixed-size')\n",
    "\n",
    "    from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "    from langchain.vectorstores import FAISS\n",
    "\n",
    "    k = 5\n",
    "    # Embedding_model = 'text-davinci-003' # text-embedding-ada-002\n",
    "    Embedding_model = 'text-embedding-ada-002' # text-embedding-ada-002\n",
    "    \n",
    "    \n",
    "    faiss_index_path = f\"../Data/chosen_papers/faiss/{Embedding_model}/faiss_index_{Embedding_model}_{paper_id}.pkl\"\n",
    "    just_load = False\n",
    "    if os.path.isfile(faiss_index_path) and just_load:\n",
    "        print('loadded Embeddings')\n",
    "        with open(faiss_index_path, \"rb\") as f:\n",
    "            faiss_index = pickle.load(f)\n",
    "    else:\n",
    "        with open(faiss_index_path, \"wb\") as f:  # text-embedding-ada-002\n",
    "            faiss_index = FAISS.from_documents(sliced_pages, OpenAIEmbeddings(model=Embedding_model))    # 'text-davinci-003\n",
    "            pickle.dump(faiss_index, f)\n",
    "\n",
    "    # faiss_index = LanceDB.from_documents(sliced_pages, OpenAIEmbeddings(model=Embedding_model))\n",
    "    \n",
    "    retriever  = faiss_index.as_retriever(search_type=\"mmr\", search_kwargs={\"k\":k, 'fetch_k': 50}) # Maximum Marginal Relevance Retrieval\n",
    "        \n",
    "    from langchain.llms import OpenAI\n",
    "    from langchain.chains import RetrievalQAWithSourcesChain\n",
    "    llm = OpenAI(temperature=0, model_name='gpt-3.5-turbo-16k') # gpt-3.5-turbo-16k\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "    result = qa({\"query\": prompt3a})\n",
    "    return result['result']\n",
    "\n",
    "# Steep uptake behavior is from this paper: https://pubs.acs.org/doi/epdf/10.1021/ja306812r\n",
    "\n",
    "prefix = \"\"\"You are an expert chemist. The doc tool describes the water stability properties of a few materials including \\\n",
    "    Metal-Organic Frameworks(MOF) or coordination polymers, Coordination Networks or ZIF compounds.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "output_format = f\"\"\"\n",
    "    Your final answer should be in JSON format contain the following keys:\\\n",
    "    Your first key is the water stability of each MOF. \\\n",
    "    Your second key for each mof should be a probability score ranging between [0, 1].\\\n",
    "    This probability score shows how certain you are in your answer.\\\n",
    "    Your third key should be exact sentences without any changes from the document that justifies your decision.\\\n",
    "    This should be \"Not provided\" if you cannot find water stability.\\\n",
    "    If there are multiple MOFs, please list them all and put \"MOF name\" before them. \\\n",
    "    Make sure it is parsable using Python json.load.\n",
    "    Make sure \"MOF name\"s do not have duplicates\n",
    "    If information is not provided, state it as not provided.\\\n",
    "        \"\"\"\n",
    "\n",
    "@tool\n",
    "def eval_justification(justification):\n",
    "    '''\n",
    "    Always use this tool at the last step. This function checks if the justification talks about the water stability. \n",
    "    '''\n",
    "    import openai\n",
    "    model=\"gpt-3.5-turbo\"\n",
    "    prompt = f\"\"\"Does the below sentence really describe information on water stability on all found MOFS?\\\n",
    "            If not remove find a better justification.\n",
    "            {justification}\n",
    "            \"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "agent_llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo-16k')\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"doc\",\n",
    "        func=qa.run,\n",
    "        description=f\"Always use this tool for context. Use the original prompt for this tool to get context about water stability of MOFs.\"\n",
    "    ), eval_justification]\n",
    "\n",
    "# tools = [doc_retrival]\n",
    "agent_chain = initialize_agent(tools, agent_llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                               verbose=True, memory=memory, handle_parsing_errors=True,\n",
    "                              prefix= None, suffix=None, output_parser=None)\n",
    "\n",
    "\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = agent_chain.run(input=prompt3a)\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7b2983a9-ea0b-4d25-b297-27d4ac1df580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bio-MOF-11': {'Predicted Stability': 'Unstable',\n",
       "  'Score': 1.0,\n",
       "  'Justification': 'Based on the information provided, the water stability of the bio-MOFs was evaluated by soaking them in water for different periods of time and then evaluating their stability using PXRD and SEM imaging. Bio-MOF-11 dissolved rapidly in water.',\n",
       "  'Paper id': '1'},\n",
       " 'bio-MOF-12': {'Predicted Stability': 'Unstable',\n",
       "  'Score': 1.0,\n",
       "  'Justification': 'Based on the information provided, the water stability of the bio-MOFs was evaluated by soaking them in water for different periods of time and then evaluating their stability using PXRD and SEM imaging. Bio-MOFs-12 dissolved partially in water.',\n",
       "  'Paper id': '1'},\n",
       " 'bio-MOF-13': {'Predicted Stability': 'Unstable',\n",
       "  'Score': 1.0,\n",
       "  'Justification': 'Based on the information provided, the water stability of the bio-MOFs was evaluated by soaking them in water for different periods of time and then evaluating their stability using PXRD and SEM imaging. Bio-MOF-13 dissolved partially in water.',\n",
       "  'Paper id': '1'},\n",
       " 'bio-MOF-14': {'Predicted Stability': 'Stable',\n",
       "  'Score': 1.0,\n",
       "  'Justification': 'Based on the information provided, the water stability of the bio-MOFs was evaluated by soaking them in water for different periods of time and then evaluating their stability using PXRD and SEM imaging. Bio-MOF-14 showed no loss of crystallinity or significant crystal degradation after soaking in water for 1 hour, 7 days, or 30 days. Additionally, CO2 isotherms collected for bio-MOF-14 soaked in water for 7 or 30 days showed no loss in crystallinity and closely matched the isotherm of the non-water-treated sample, indicating that water did not affect the porosity of the material.',\n",
       "  'Paper id': '1'}}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_to_dict(result, paper_id):\n",
    "    from typing import List\n",
    "    from langchain.output_parsers import PydanticOutputParser, OutputFixingParser\n",
    "    from pydantic import BaseModel, Field, validator\n",
    "\n",
    "    class MOF(BaseModel):\n",
    "        name: str = Field(description=\"name of a MOF\")\n",
    "        stability: str = Field(description=\"choose only one: stable or unstable or not provided\")\n",
    "        score: float = Field(description=\"probability score of prediction\")\n",
    "        justification: str = Field(description=\"justification for prediction\")\n",
    "\n",
    "    class MOFList(BaseModel):\n",
    "        MOFs: List[MOF]\n",
    "\n",
    "    parser = PydanticOutputParser(pydantic_object=MOFList)\n",
    "    llm_parser = OutputFixingParser.from_llm(parser=parser, llm=ChatOpenAI(temperature=0))\n",
    "\n",
    "    try:\n",
    "        parsed_result = llm_parser.parse(result)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Failed to parse MOF: {e}\")\n",
    "\n",
    "    dict_response = {mof.name: {\"Predicted Stability\": mof.stability, \"Score\": mof.score, \"Justification\": mof.justification} for mof in parsed_result.MOFs}\n",
    "    new_dict = {key: {**value, 'Paper id': paper_id} for key, value in dict_response.items()}\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "parse_to_dict(result, paper_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861011c0-d6d6-459d-93d7-9d7492164e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "agent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
